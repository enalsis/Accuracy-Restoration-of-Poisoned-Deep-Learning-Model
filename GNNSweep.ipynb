{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5410,"status":"ok","timestamp":1731150426670,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-60},"id":"3y5sSdEfwVO4","outputId":"8692a23b-7132-4568-e761-11b7300ccc49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n"]}],"source":["!pip install torch-geometric\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41195,"status":"ok","timestamp":1729362585309,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"9EomXoewCjdR","outputId":"12c9639b-7972-4fd5-a611-6e33c51265e6"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n","Processing...\n","Done!\n"]},{"name":"stdout","output_type":"stream","text":["Training the model on clean data...\n","Epoch 0, Loss: 1.9546961784362793\n","Epoch 10, Loss: 0.6961610913276672\n","Epoch 20, Loss: 0.19654710590839386\n","Epoch 30, Loss: 0.0737478956580162\n","Epoch 40, Loss: 0.07014885544776917\n","Epoch 50, Loss: 0.04678536579012871\n","Epoch 60, Loss: 0.04055462405085564\n","Epoch 70, Loss: 0.04191984608769417\n","Epoch 80, Loss: 0.04423925653100014\n","Epoch 90, Loss: 0.04605355113744736\n","Epoch 100, Loss: 0.03145918250083923\n","Epoch 110, Loss: 0.02058337815105915\n","Epoch 120, Loss: 0.035183221101760864\n","Epoch 130, Loss: 0.02580614574253559\n","Epoch 140, Loss: 0.03164217993617058\n","Epoch 150, Loss: 0.024084553122520447\n","Epoch 160, Loss: 0.03014778345823288\n","Epoch 170, Loss: 0.02581222914159298\n","Epoch 180, Loss: 0.03662600368261337\n","Epoch 190, Loss: 0.03895122930407524\n","Accuracy on clean data: 0.7980\n","Injecting backdoor attack into 5 nodes\n","Training the model on poisoned data...\n","Epoch 0, Loss: 0.09548074007034302\n","Epoch 10, Loss: 0.03162235766649246\n","Epoch 20, Loss: 0.02893128991127014\n","Epoch 30, Loss: 0.02345961146056652\n","Epoch 40, Loss: 0.012219534255564213\n","Epoch 50, Loss: 0.03401465341448784\n","Epoch 60, Loss: 0.016157204285264015\n","Epoch 70, Loss: 0.022668397054076195\n","Epoch 80, Loss: 0.020596198737621307\n","Epoch 90, Loss: 0.009805327281355858\n","Epoch 100, Loss: 0.011426030658185482\n","Epoch 110, Loss: 0.01967884600162506\n","Epoch 120, Loss: 0.017364690080285072\n","Epoch 130, Loss: 0.01686345599591732\n","Epoch 140, Loss: 0.017283881083130836\n","Epoch 150, Loss: 0.029598988592624664\n","Epoch 160, Loss: 0.015311304479837418\n","Epoch 170, Loss: 0.027316026389598846\n","Epoch 180, Loss: 0.015102945268154144\n","Epoch 190, Loss: 0.016174864023923874\n","Accuracy on poisoned data: 0.7910\n","Detected 204 anomalous nodes\n","Retraining the model after removing poisoned nodes...\n","Epoch 0, Loss: 0.020164577290415764\n","Epoch 10, Loss: 0.022443588823080063\n","Epoch 20, Loss: 0.020394260063767433\n","Epoch 30, Loss: 0.02157033607363701\n","Epoch 40, Loss: 0.021531321108341217\n","Epoch 50, Loss: 0.028127843514084816\n","Epoch 60, Loss: 0.02296723797917366\n","Epoch 70, Loss: 0.025385383516550064\n","Epoch 80, Loss: 0.022406281903386116\n","Epoch 90, Loss: 0.02661156840622425\n","Epoch 100, Loss: 0.026159605011343956\n","Epoch 110, Loss: 0.015633048489689827\n","Epoch 120, Loss: 0.013656851835548878\n","Epoch 130, Loss: 0.017087914049625397\n","Epoch 140, Loss: 0.011947667226195335\n","Epoch 150, Loss: 0.03350583091378212\n","Epoch 160, Loss: 0.02288605459034443\n","Epoch 170, Loss: 0.015179486945271492\n","Epoch 180, Loss: 0.013757465407252312\n","Epoch 190, Loss: 0.013633370399475098\n","Accuracy after defense: 0.8130\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import add_self_loops, to_networkx\n","import networkx as nx\n","import random\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define a simple GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(in_channels, 16)\n","        self.conv2 = GCNConv(16, out_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load data\n","data = dataset[0]\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","data = data.to(device)\n","\n","# Train the GCN model\n","def train(model, data):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    model.train()\n","\n","    for epoch in range(200):\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","        if epoch % 10 == 0:\n","            print(f'Epoch {epoch}, Loss: {loss.item()}')\n","\n","# Evaluate the model\n","def test(model, data):\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n","    acc = int(correct) / int(data.test_mask.sum())\n","    return acc\n","\n","# Backdoor Attack Injection (Poisoning)\n","def inject_backdoor(data, num_poisoned_nodes=5):\n","    print(f\"Injecting backdoor attack into {num_poisoned_nodes} nodes\")\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_poisoned_nodes)\n","    for node in poisoned_nodes:\n","        data.x[node] = torch.rand_like(data.x[node])  # Randomize features as trigger\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","    return data, poisoned_nodes\n","\n","# Anomaly Detection (Simple Defense)\n","def detect_anomalous_nodes(data):\n","    G = to_networkx(data, to_undirected=True)\n","    degrees = nx.degree_centrality(G)\n","\n","    # Find nodes with degree centrality significantly higher than others\n","    threshold = 2 * sum(degrees.values()) / len(degrees)\n","    anomalous_nodes = [node for node, degree in degrees.items() if degree > threshold]\n","    print(f\"Detected {len(anomalous_nodes)} anomalous nodes\")\n","    return anomalous_nodes\n","\n","# Main execution\n","print(\"Training the model on clean data...\")\n","train(model, data)\n","acc_clean = test(model, data)\n","print(f\"Accuracy on clean data: {acc_clean:.4f}\")\n","\n","# Inject backdoor attacks\n","data, poisoned_nodes = inject_backdoor(data, num_poisoned_nodes=5)\n","\n","print(\"Training the model on poisoned data...\")\n","train(model, data)\n","acc_poisoned = test(model, data)\n","print(f\"Accuracy on poisoned data: {acc_poisoned:.4f}\")\n","\n","# Detect and filter anomalous nodes\n","anomalous_nodes = detect_anomalous_nodes(data)\n","\n","# Fine-tune the model without poisoned nodes\n","def remove_poisoned_nodes(data, poisoned_nodes):\n","    data.train_mask[poisoned_nodes] = False  # Remove poisoned nodes from the training set\n","    return data\n","\n","data = remove_poisoned_nodes(data, poisoned_nodes)\n","print(\"Retraining the model after removing poisoned nodes...\")\n","train(model, data)\n","acc_defended = test(model, data)\n","print(f\"Accuracy after defense: {acc_defended:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37263,"status":"ok","timestamp":1729363570440,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"XUxwWjqMCkNY","outputId":"d200a745-6d0a-4014-81b0-190a0e82130c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the model on clean data...\n","Epoch 0, Loss: 1.9507275819778442\n","Epoch 10, Loss: 0.7671340703964233\n","Epoch 20, Loss: 0.23847250640392303\n","Epoch 30, Loss: 0.14077916741371155\n","Epoch 40, Loss: 0.06796666234731674\n","Epoch 50, Loss: 0.05183885619044304\n","Epoch 60, Loss: 0.057986531406641006\n","Epoch 70, Loss: 0.03404968976974487\n","Epoch 80, Loss: 0.037949733436107635\n","Epoch 90, Loss: 0.03004702925682068\n","Epoch 100, Loss: 0.030838390812277794\n","Epoch 110, Loss: 0.031211528927087784\n","Epoch 120, Loss: 0.04458938166499138\n","Epoch 130, Loss: 0.02715941146016121\n","Epoch 140, Loss: 0.046850357204675674\n","Epoch 150, Loss: 0.026798702776432037\n","Epoch 160, Loss: 0.02269257791340351\n","Epoch 170, Loss: 0.03319086879491806\n","Epoch 180, Loss: 0.029623253270983696\n","Epoch 190, Loss: 0.023200623691082\n","Accuracy on clean data: 0.8080\n","Injecting feature backdoor attack into 5 nodes\n","Injecting edge backdoor attack with 10 edges\n","Injecting trigger-based backdoor attack into 5 nodes\n","Training the model on poisoned data...\n","Epoch 0, Loss: 0.021096497774124146\n","Epoch 10, Loss: 0.02911263145506382\n","Epoch 20, Loss: 0.02262123115360737\n","Epoch 30, Loss: 0.029961852356791496\n","Epoch 40, Loss: 0.03248094767332077\n","Epoch 50, Loss: 0.02979172207415104\n","Epoch 60, Loss: 0.019549213349819183\n","Epoch 70, Loss: 0.011897845193743706\n","Epoch 80, Loss: 0.024859927594661713\n","Epoch 90, Loss: 0.015472008846700191\n","Epoch 100, Loss: 0.012734613381326199\n","Epoch 110, Loss: 0.024770749732851982\n","Epoch 120, Loss: 0.023874757811427116\n","Epoch 130, Loss: 0.013327894732356071\n","Epoch 140, Loss: 0.022308211773633957\n","Epoch 150, Loss: 0.025619011372327805\n","Epoch 160, Loss: 0.014728040434420109\n","Epoch 170, Loss: 0.01924535632133484\n","Epoch 180, Loss: 0.02287858910858631\n","Epoch 190, Loss: 0.023294974118471146\n","Accuracy on poisoned data: 0.8050\n","Community detection identified 227 potentially poisoned nodes\n","PCA-based embedding filter identified 10 potentially poisoned nodes\n","Spectral analysis identified 56 potentially poisoned nodes\n","Retraining the model after filtering potentially poisoned nodes...\n","Epoch 0, Loss: 0.027229085564613342\n","Epoch 10, Loss: 0.03867582604289055\n","Epoch 20, Loss: 0.015554683282971382\n","Epoch 30, Loss: 0.011821618303656578\n","Epoch 40, Loss: 0.004095518030226231\n","Epoch 50, Loss: 0.009121124632656574\n","Epoch 60, Loss: 0.04258867725729942\n","Epoch 70, Loss: 0.0071040671318769455\n","Epoch 80, Loss: 0.010267956182360649\n","Epoch 90, Loss: 0.011848903261125088\n","Epoch 100, Loss: 0.0052582453936338425\n","Epoch 110, Loss: 0.00854506716132164\n","Epoch 120, Loss: 0.03610068932175636\n","Epoch 130, Loss: 0.012354237958788872\n","Epoch 140, Loss: 0.01207991037517786\n","Epoch 150, Loss: 0.011593092232942581\n","Epoch 160, Loss: 0.009244091808795929\n","Epoch 170, Loss: 0.02168085239827633\n","Epoch 180, Loss: 0.01569039188325405\n","Epoch 190, Loss: 0.00649705296382308\n","Accuracy after defense: 0.5480\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import to_networkx, add_self_loops, remove_self_loops\n","import random\n","import networkx as nx\n","from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define a simple GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(in_channels, 16)\n","        self.conv2 = GCNConv(16, out_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load data\n","data = dataset[0]\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","data = data.to(device)\n","\n","# Train the GCN model\n","def train(model, data):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    model.train()\n","\n","    for epoch in range(200):\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","        if epoch % 10 == 0:\n","            print(f'Epoch {epoch}, Loss: {loss.item()}')\n","\n","# Evaluate the model\n","def test(model, data):\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n","    acc = int(correct) / int(data.test_mask.sum())\n","    return acc\n","\n","# Backdoor Attack 1: Feature-based Poisoning (Add triggers to node features)\n","def inject_feature_attack(data, num_poisoned_nodes=5):\n","    print(f\"Injecting feature backdoor attack into {num_poisoned_nodes} nodes\")\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_poisoned_nodes)\n","    for node in poisoned_nodes:\n","        data.x[node] = torch.rand_like(data.x[node])  # Randomize features as a trigger\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","    return data, poisoned_nodes\n","\n","# Backdoor Attack 2: Edge-based Poisoning (Add random edges)\n","def inject_edge_attack(data, num_poisoned_edges=10):\n","    print(f\"Injecting edge backdoor attack with {num_poisoned_edges} edges\")\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    poisoned_edges = []\n","    for _ in range(num_poisoned_edges):\n","        node1 = random.randint(0, data.num_nodes - 1)\n","        node2 = random.randint(0, data.num_nodes - 1)\n","        poisoned_edges.append([node1, node2])\n","    poisoned_edges = torch.tensor(poisoned_edges, dtype=torch.long).t().contiguous()\n","    data.edge_index = torch.cat([edge_index, poisoned_edges], dim=1)\n","    return data, poisoned_edges\n","\n","# Backdoor Attack 3: Trigger-based Poisoning (Feature + Edge modification)\n","def inject_trigger_attack(data, num_trigger_nodes=5, trigger_pattern=None):\n","    print(f\"Injecting trigger-based backdoor attack into {num_trigger_nodes} nodes\")\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_trigger_nodes)\n","    if trigger_pattern is None:\n","        trigger_pattern = torch.ones(data.num_node_features)\n","\n","    for node in poisoned_nodes:\n","        data.x[node] = trigger_pattern  # Set a specific trigger pattern in features\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","\n","    # Add edges between poisoned nodes (trigger behavior)\n","    for i in range(num_trigger_nodes):\n","        for j in range(i + 1, num_trigger_nodes):\n","            data.edge_index = torch.cat([data.edge_index, torch.tensor([[poisoned_nodes[i]], [poisoned_nodes[j]]], dtype=torch.long)], dim=1)\n","\n","    return data, poisoned_nodes\n","\n","# Filtration Method 1: Community Detection-Based Filtration\n","def community_detection_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    communities = nx.algorithms.community.greedy_modularity_communities(G)\n","    filtered_nodes = []\n","\n","    # Assuming smaller communities are potentially poisoned\n","    for community in communities:\n","        if len(community) < 10:  # Arbitrary threshold\n","            filtered_nodes.extend(list(community))\n","\n","    print(f\"Community detection identified {len(filtered_nodes)} potentially poisoned nodes\")\n","    return filtered_nodes\n","\n","# Filtration Method 2: PCA Embedding-Based Detection\n","def pca_embedding_filter(data, n_components=2):\n","    X = data.x.cpu().detach().numpy()\n","    pca = PCA(n_components=n_components)\n","    X_pca = pca.fit_transform(X)\n","\n","    # Compute distances from the mean of embeddings\n","    distances = np.linalg.norm(X_pca - X_pca.mean(axis=0), axis=1)\n","    threshold = np.mean(distances) + 2 * np.std(distances)  # Arbitrary threshold\n","    filtered_nodes = np.where(distances > threshold)[0]\n","\n","    print(f\"PCA-based embedding filter identified {len(filtered_nodes)} potentially poisoned nodes\")\n","    return filtered_nodes\n","\n","# Filtration Method 3: Spectral Analysis (Graph Laplacian)\n","def spectral_analysis_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    laplacian_matrix = nx.laplacian_matrix(G).toarray()\n","    eigenvalues = np.linalg.eigvals(laplacian_matrix)\n","\n","    # Identify anomalies by analyzing the spectrum of eigenvalues\n","    threshold = np.mean(eigenvalues) + 2 * np.std(eigenvalues)  # Arbitrary threshold\n","    filtered_nodes = [i for i, e in enumerate(eigenvalues) if e > threshold]\n","\n","    print(f\"Spectral analysis identified {len(filtered_nodes)} potentially poisoned nodes\")\n","    return filtered_nodes\n","\n","# Main Execution\n","\n","# Train on clean data\n","print(\"Training the model on clean data...\")\n","train(model, data)\n","acc_clean = test(model, data)\n","print(f\"Accuracy on clean data: {acc_clean:.4f}\")\n","\n","# Inject feature-based backdoor attack\n","data, poisoned_nodes_feat = inject_feature_attack(data, num_poisoned_nodes=5)\n","\n","# Inject edge-based backdoor attack\n","data, poisoned_edges = inject_edge_attack(data, num_poisoned_edges=10)\n","\n","# Inject trigger-based backdoor attack\n","trigger_pattern = torch.ones(data.num_node_features) * 0.5  # Custom trigger pattern\n","data, poisoned_nodes_trigger = inject_trigger_attack(data, num_trigger_nodes=5, trigger_pattern=trigger_pattern)\n","\n","# Retrain on poisoned data\n","print(\"Training the model on poisoned data...\")\n","train(model, data)\n","acc_poisoned = test(model, data)\n","print(f\"Accuracy on poisoned data: {acc_poisoned:.4f}\")\n","\n","# Apply community detection filtration\n","community_filtered_nodes = community_detection_filter(data)\n","\n","# Apply PCA embedding-based filtration\n","pca_filtered_nodes = pca_embedding_filter(data)\n","\n","# Apply spectral analysis filtration\n","spectral_filtered_nodes = spectral_analysis_filter(data)\n","\n","# Final Retraining after filtering poisoned nodes\n","def remove_filtered_nodes(data, filtered_nodes):\n","    data.train_mask[filtered_nodes] = False  # Remove poisoned nodes from training\n","    return data\n","\n","# Combine all filtered nodes and retrain\n","all_filtered_nodes = set(community_filtered_nodes).union(pca_filtered_nodes).union(spectral_filtered_nodes)\n","data = remove_filtered_nodes(data, list(all_filtered_nodes))\n","\n","print(\"Retraining the model after filtering potentially poisoned nodes...\")\n","train(model, data)\n","acc_defended = test(model, data)\n","print(f\"Accuracy after defense: {acc_defended:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43138,"status":"ok","timestamp":1729363774567,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"FsvGvKd4Eeat","outputId":"55b07115-83fd-4e0b-8313-dc05ea37ce30"},"outputs":[{"name":"stdout","output_type":"stream","text":["===== Feature-based Attack and Community Detection Filtration =====\n","Injecting feature backdoor attack into 5 nodes\n","Training the model on poisoned data...\n","Accuracy on poisoned data (feature-based attack): 0.8100\n","Community detection identified 245 potentially poisoned nodes\n","Retraining the model after community detection filtering...\n","Accuracy after community detection filter (feature-based attack): 0.7930\n","\n","===== Edge-based Attack and PCA Embedding Filtration =====\n","Injecting edge backdoor attack with 10 edges\n","Training the model on poisoned data...\n","Accuracy on poisoned data (edge-based attack): 0.7700\n","PCA-based embedding filter identified 5 potentially poisoned nodes\n","Retraining the model after PCA embedding filtering...\n","Accuracy after PCA embedding filter (edge-based attack): 0.7640\n","\n","===== Trigger-based Attack and Spectral Analysis Filtration =====\n","Injecting feature backdoor attack into 5 nodes\n","Training the model on poisoned data...\n","Accuracy on poisoned data (trigger-based attack): 0.7940\n","Spectral analysis identified 56 potentially poisoned nodes\n","Retraining the model after spectral analysis filtering...\n","Accuracy after spectral analysis filter (trigger-based attack): 0.5490\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import to_networkx, add_self_loops, remove_self_loops\n","import random\n","import networkx as nx\n","from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define a simple GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(in_channels, 16)\n","        self.conv2 = GCNConv(16, out_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load data\n","data = dataset[0]\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","data = data.to(device)\n","\n","# Train the GCN model\n","def train(model, data):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    model.train()\n","\n","    for epoch in range(200):\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the model\n","def test(model, data):\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n","    acc = int(correct) / int(data.test_mask.sum())\n","    return acc\n","\n","# Backdoor Attack 1: Feature-based Poisoning\n","def inject_feature_attack(data, num_poisoned_nodes=5):\n","    print(f\"Injecting feature backdoor attack into {num_poisoned_nodes} nodes\")\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_poisoned_nodes)\n","    for node in poisoned_nodes:\n","        data.x[node] = torch.rand_like(data.x[node])  # Randomize features as a trigger\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","    return data, poisoned_nodes\n","\n","# Backdoor Attack 2: Edge-based Poisoning\n","def inject_edge_attack(data, num_poisoned_edges=10):\n","    print(f\"Injecting edge backdoor attack with {num_poisoned_edges} edges\")\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    poisoned_edges = []\n","    for _ in range(num_poisoned_edges):\n","        node1 = random.randint(0, data.num_nodes - 1)\n","        node2 = random.randint(0, data.num_nodes - 1)\n","        poisoned_edges.append([node1, node2])\n","    poisoned_edges = torch.tensor(poisoned_edges, dtype=torch.long).t().contiguous()\n","    data.edge_index = torch.cat([edge_index, poisoned_edges], dim=1)\n","    return data, poisoned_edges\n","\n","# Filtration Method 1: Community Detection-Based Filtration\n","def community_detection_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    communities = nx.algorithms.community.greedy_modularity_communities(G)\n","    filtered_nodes = []\n","\n","    # Assuming smaller communities are potentially poisoned\n","    for community in communities:\n","        if len(community) < 10:  # Arbitrary threshold\n","            filtered_nodes.extend(list(community))\n","\n","    print(f\"Community detection identified {len(filtered_nodes)} potentially poisoned nodes\")\n","    return filtered_nodes\n","\n","# Filtration Method 2: PCA Embedding-Based Detection\n","def pca_embedding_filter(data, n_components=2):\n","    X = data.x.cpu().detach().numpy()\n","    pca = PCA(n_components=n_components)\n","    X_pca = pca.fit_transform(X)\n","\n","    # Compute distances from the mean of embeddings\n","    distances = np.linalg.norm(X_pca - X_pca.mean(axis=0), axis=1)\n","    threshold = np.mean(distances) + 2 * np.std(distances)  # Arbitrary threshold\n","    filtered_nodes = np.where(distances > threshold)[0]\n","\n","    print(f\"PCA-based embedding filter identified {len(filtered_nodes)} potentially poisoned nodes\")\n","    return filtered_nodes\n","\n","# Final Retraining after filtering poisoned nodes\n","def remove_filtered_nodes(data, filtered_nodes):\n","    data.train_mask[filtered_nodes] = False  # Remove poisoned nodes from training\n","    return data\n","\n","# Apply backdoor attacks and filtration one by one\n","\n","# 1. Apply Feature-based Attack and Community Detection\n","print(\"===== Feature-based Attack and Community Detection Filtration =====\")\n","data, poisoned_nodes_feat = inject_feature_attack(data, num_poisoned_nodes=5)\n","print(\"Training the model on poisoned data...\")\n","train(model, data)\n","acc_poisoned_feat = test(model, data)\n","print(f\"Accuracy on poisoned data (feature-based attack): {acc_poisoned_feat:.4f}\")\n","\n","# Apply community detection filter\n","community_filtered_nodes = community_detection_filter(data)\n","data = remove_filtered_nodes(data, community_filtered_nodes)\n","print(\"Retraining the model after community detection filtering...\")\n","train(model, data)\n","acc_defended_feat = test(model, data)\n","print(f\"Accuracy after community detection filter (feature-based attack): {acc_defended_feat:.4f}\")\n","\n","# 2. Apply Edge-based Attack and PCA Embedding Filtration\n","print(\"\\n===== Edge-based Attack and PCA Embedding Filtration =====\")\n","data, poisoned_edges = inject_edge_attack(data, num_poisoned_edges=10)\n","print(\"Training the model on poisoned data...\")\n","train(model, data)\n","acc_poisoned_edge = test(model, data)\n","print(f\"Accuracy on poisoned data (edge-based attack): {acc_poisoned_edge:.4f}\")\n","\n","# Apply PCA embedding-based filter\n","pca_filtered_nodes = pca_embedding_filter(data)\n","data = remove_filtered_nodes(data, pca_filtered_nodes)\n","print(\"Retraining the model after PCA embedding filtering...\")\n","train(model, data)\n","acc_defended_edge = test(model, data)\n","print(f\"Accuracy after PCA embedding filter (edge-based attack): {acc_defended_edge:.4f}\")\n","\n","# 3. Apply Trigger-based Attack and Spectral Analysis\n","print(\"\\n===== Trigger-based Attack and Spectral Analysis Filtration =====\")\n","trigger_pattern = torch.ones(data.num_node_features) * 0.5  # Custom trigger pattern\n","data, poisoned_nodes_trigger = inject_feature_attack(data, num_poisoned_nodes=5)\n","print(\"Training the model on poisoned data...\")\n","train(model, data)\n","acc_poisoned_trigger = test(model, data)\n","print(f\"Accuracy on poisoned data (trigger-based attack): {acc_poisoned_trigger:.4f}\")\n","\n","# Apply spectral analysis filtration\n","def spectral_analysis_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    laplacian_matrix = nx.laplacian_matrix(G).toarray()\n","    eigenvalues = np.linalg.eigvals(laplacian_matrix)\n","\n","    # Identify anomalies by analyzing the spectrum of eigenvalues\n","    threshold = np.mean(eigenvalues) + 2 * np.std(eigenvalues)  # Arbitrary threshold\n","    filtered_nodes = [i for i, e in enumerate(eigenvalues) if e > threshold]\n","\n","    print(f\"Spectral analysis identified {len(filtered_nodes)} potentially poisoned nodes\")\n","    return filtered_nodes\n","\n","spectral_filtered_nodes = spectral_analysis_filter(data)\n","data = remove_filtered_nodes(data, spectral_filtered_nodes)\n","print(\"Retraining the model after spectral analysis filtering...\")\n","train(model, data)\n","acc_defended_trigger = test(model, data)\n","print(f\"Accuracy after spectral analysis filter (trigger-based attack): {acc_defended_trigger:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128515,"status":"ok","timestamp":1729364235804,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"kTKoj0R2HF-J","outputId":"e78ffae6-512b-4e85-aa20-a15199bbc8de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the model on clean data...\n","Clean Accuracy: 0.8030\n","\n","===== Feature-based Attack and Community Detection Filtration =====\n","Training the model on poisoned data (Feature-based Attack)...\n","Accuracy on poisoned data (Feature-based Attack): 0.8060\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Feature-based Attack): 0.7920\n","\n","===== Feature-based Attack and PCA Embedding Filtration =====\n","Training the model on poisoned data (Feature-based Attack)...\n","Accuracy on poisoned data (Feature-based Attack): 0.7920\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Feature-based Attack): 0.8080\n","\n","===== Feature-based Attack and Spectral Analysis Filtration =====\n","Training the model on poisoned data (Feature-based Attack)...\n","Accuracy on poisoned data (Feature-based Attack): 0.8030\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Feature-based Attack): 0.5610\n","\n","===== Edge-based Attack and Community Detection Filtration =====\n","Training the model on poisoned data (Edge-based Attack)...\n","Accuracy on poisoned data (Edge-based Attack): 0.7980\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Edge-based Attack): 0.7930\n","\n","===== Edge-based Attack and PCA Embedding Filtration =====\n","Training the model on poisoned data (Edge-based Attack)...\n","Accuracy on poisoned data (Edge-based Attack): 0.8060\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Edge-based Attack): 0.7910\n","\n","===== Edge-based Attack and Spectral Analysis Filtration =====\n","Training the model on poisoned data (Edge-based Attack)...\n","Accuracy on poisoned data (Edge-based Attack): 0.7900\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Edge-based Attack): 0.5550\n","\n","===== Trigger-based Attack and Community Detection Filtration =====\n","Training the model on poisoned data (Trigger-based Attack)...\n","Accuracy on poisoned data (Trigger-based Attack): 0.7880\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Trigger-based Attack): 0.7810\n","\n","===== Trigger-based Attack and PCA Embedding Filtration =====\n","Training the model on poisoned data (Trigger-based Attack)...\n","Accuracy on poisoned data (Trigger-based Attack): 0.8050\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Trigger-based Attack): 0.8110\n","\n","===== Trigger-based Attack and Spectral Analysis Filtration =====\n","Training the model on poisoned data (Trigger-based Attack)...\n","Accuracy on poisoned data (Trigger-based Attack): 0.7870\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Trigger-based Attack): 0.5500\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import to_networkx, add_self_loops, remove_self_loops\n","import random\n","import networkx as nx\n","from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define a simple GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(in_channels, 16)\n","        self.conv2 = GCNConv(16, out_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load data\n","original_data = dataset[0]  # Save the original dataset separately\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Train the GCN model\n","def train(model, data):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    model.train()\n","\n","    for epoch in range(200):\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the model\n","def test(model, data):\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n","    acc = int(correct) / int(data.test_mask.sum())\n","    return acc\n","\n","# Backdoor Attack 1: Feature-based Poisoning\n","def inject_feature_attack(data, num_poisoned_nodes=5):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_poisoned_nodes)\n","    for node in poisoned_nodes:\n","        data.x[node] = torch.rand_like(data.x[node])  # Randomize features as a trigger\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","    return data, poisoned_nodes\n","\n","# Backdoor Attack 2: Edge-based Poisoning\n","def inject_edge_attack(data, num_poisoned_edges=10):\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    poisoned_edges = []\n","    for _ in range(num_poisoned_edges):\n","        node1 = random.randint(0, data.num_nodes - 1)\n","        node2 = random.randint(0, data.num_nodes - 1)\n","        poisoned_edges.append([node1, node2])\n","    poisoned_edges = torch.tensor(poisoned_edges, dtype=torch.long).t().contiguous()\n","    data.edge_index = torch.cat([edge_index, poisoned_edges], dim=1)\n","    return data, poisoned_edges\n","\n","# Backdoor Attack 3: Trigger-based Poisoning\n","def inject_trigger_attack(data, num_trigger_nodes=5, trigger_pattern=None):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_trigger_nodes)\n","    if trigger_pattern is None:\n","        trigger_pattern = torch.ones(data.num_node_features)\n","\n","    for node in poisoned_nodes:\n","        data.x[node] = trigger_pattern  # Set a specific trigger pattern in features\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","\n","    return data, poisoned_nodes\n","\n","# Filtration Method 1: Community Detection-Based Filtration\n","def community_detection_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    communities = nx.algorithms.community.greedy_modularity_communities(G)\n","    filtered_nodes = []\n","\n","    # Assuming smaller communities are potentially poisoned\n","    for community in communities:\n","        if len(community) < 10:  # Arbitrary threshold\n","            filtered_nodes.extend(list(community))\n","\n","    return filtered_nodes\n","\n","# Filtration Method 2: PCA Embedding-Based Detection\n","def pca_embedding_filter(data, n_components=2):\n","    X = data.x.cpu().detach().numpy()\n","    pca = PCA(n_components=n_components)\n","    X_pca = pca.fit_transform(X)\n","\n","    # Compute distances from the mean of embeddings\n","    distances = np.linalg.norm(X_pca - X_pca.mean(axis=0), axis=1)\n","    threshold = np.mean(distances) + 2 * np.std(distances)  # Arbitrary threshold\n","    filtered_nodes = np.where(distances > threshold)[0]\n","\n","    return filtered_nodes\n","\n","# Filtration Method 3: Spectral Analysis\n","def spectral_analysis_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    laplacian_matrix = nx.laplacian_matrix(G).toarray()\n","    eigenvalues = np.linalg.eigvals(laplacian_matrix)\n","\n","    # Identify anomalies by analyzing the spectrum of eigenvalues\n","    threshold = np.mean(eigenvalues) + 2 * np.std(eigenvalues)  # Arbitrary threshold\n","    filtered_nodes = [i for i, e in enumerate(eigenvalues) if e > threshold]\n","\n","    return filtered_nodes\n","\n","# Final Retraining after filtering poisoned nodes\n","def remove_filtered_nodes(data, filtered_nodes):\n","    data.train_mask[filtered_nodes] = False  # Remove poisoned nodes from training\n","    return data\n","\n","# Train on clean data\n","def run_clean_model():\n","    print(\"Training the model on clean data...\")\n","    data = original_data.clone().to(device)  # Reset to original clean data\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","    train(model, data)\n","    acc_clean = test(model, data)\n","    print(f\"Clean Accuracy: {acc_clean:.4f}\")\n","    return acc_clean\n","\n","# Function to execute one case\n","def run_case(attack_func, filter_func, attack_name, filter_name):\n","    print(f\"\\n===== {attack_name} and {filter_name} Filtration =====\")\n","\n","    # Step 1: Reset to original clean data before attack\n","    data = original_data.clone().to(device)\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","\n","    # Step 2: Apply Backdoor Attack\n","    data, poisoned_nodes = attack_func(data)\n","    print(f\"Training the model on poisoned data ({attack_name})...\")\n","    train(model, data)\n","    acc_poisoned = test(model, data)\n","    print(f\"Accuracy on poisoned data ({attack_name}): {acc_poisoned:.4f}\")\n","\n","    # Step 3: Apply Filtration\n","    filtered_nodes = filter_func(data)\n","    data = remove_filtered_nodes(data, filtered_nodes)\n","\n","    print(f\"Retraining the model after {filter_name} filtering...\")\n","    train(model, data)\n","    acc_defended = test(model, data)\n","    print(f\"Accuracy after {filter_name} filter ({attack_name}): {acc_defended:.4f}\")\n","\n","# Running all 9 cases\n","attacks = [(inject_feature_attack, \"Feature-based Attack\"),\n","           (inject_edge_attack, \"Edge-based Attack\"),\n","           (inject_trigger_attack, \"Trigger-based Attack\")]\n","\n","filters = [(community_detection_filter, \"Community Detection\"),\n","           (pca_embedding_filter, \"PCA Embedding\"),\n","           (spectral_analysis_filter, \"Spectral Analysis\")]\n","\n","# First, show the clean accuracy\n","clean_accuracy = run_clean_model()\n","\n","# Now, run all 9 combinations of attacks and filtrations\n","for attack_func, attack_name in attacks:\n","    for filter_func, filter_name in filters:\n","        run_case(attack_func, filter_func, attack_name, filter_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":127217,"status":"ok","timestamp":1729364520635,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"eukHgOG_IDwu","outputId":"836c69b5-ac16-40d7-8576-338be8d9aead"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the model on clean data...\n","Clean Accuracy: 0.8150\n","\n","===== Feature-based Attack and Community Detection Filtration =====\n","Training the model on poisoned data (Feature-based Attack)...\n","Accuracy on poisoned data (Feature-based Attack): 0.7920\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Feature-based Attack): 0.7870\n","\n","===== Feature-based Attack and PCA Embedding Filtration =====\n","Training the model on poisoned data (Feature-based Attack)...\n","Accuracy on poisoned data (Feature-based Attack): 0.8100\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Feature-based Attack): 0.8010\n","\n","===== Feature-based Attack and Spectral Analysis Filtration =====\n","Training the model on poisoned data (Feature-based Attack)...\n","Accuracy on poisoned data (Feature-based Attack): 0.7890\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Feature-based Attack): 0.5630\n","\n","===== Edge-based Attack and Community Detection Filtration =====\n","Training the model on poisoned data (Edge-based Attack)...\n","Accuracy on poisoned data (Edge-based Attack): 0.8050\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Edge-based Attack): 0.7970\n","\n","===== Edge-based Attack and PCA Embedding Filtration =====\n","Training the model on poisoned data (Edge-based Attack)...\n","Accuracy on poisoned data (Edge-based Attack): 0.8070\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Edge-based Attack): 0.8020\n","\n","===== Edge-based Attack and Spectral Analysis Filtration =====\n","Training the model on poisoned data (Edge-based Attack)...\n","Accuracy on poisoned data (Edge-based Attack): 0.8090\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Edge-based Attack): 0.5650\n","\n","===== Trigger-based Attack and Community Detection Filtration =====\n","Training the model on poisoned data (Trigger-based Attack)...\n","Accuracy on poisoned data (Trigger-based Attack): 0.8020\n","Backdoor Nodes Identified: 1/5\n","Percentage of Backdoor Nodes Removed: 20.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Trigger-based Attack): 0.7970\n","\n","===== Trigger-based Attack and PCA Embedding Filtration =====\n","Training the model on poisoned data (Trigger-based Attack)...\n","Accuracy on poisoned data (Trigger-based Attack): 0.8060\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Trigger-based Attack): 0.7930\n","\n","===== Trigger-based Attack and Spectral Analysis Filtration =====\n","Training the model on poisoned data (Trigger-based Attack)...\n","Accuracy on poisoned data (Trigger-based Attack): 0.7980\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Trigger-based Attack): 0.5550\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import to_networkx, remove_self_loops\n","import random\n","import networkx as nx\n","from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define a simple GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(in_channels, 16)\n","        self.conv2 = GCNConv(16, out_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load data\n","original_data = dataset[0]  # Save the original dataset separately\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Train the GCN model\n","def train(model, data):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    model.train()\n","\n","    for epoch in range(200):\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the model\n","def test(model, data):\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n","    acc = int(correct) / int(data.test_mask.sum())\n","    return acc\n","\n","# Backdoor Attack 1: Feature-based Poisoning\n","def inject_feature_attack(data, num_poisoned_nodes=5):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_poisoned_nodes)\n","    for node in poisoned_nodes:\n","        data.x[node] = torch.rand_like(data.x[node])  # Randomize features as a trigger\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","    return data, poisoned_nodes\n","\n","# Backdoor Attack 2: Edge-based Poisoning\n","def inject_edge_attack(data, num_poisoned_edges=10):\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    poisoned_edges = []\n","    for _ in range(num_poisoned_edges):\n","        node1 = random.randint(0, data.num_nodes - 1)\n","        node2 = random.randint(0, data.num_nodes - 1)\n","        poisoned_edges.append([node1, node2])\n","    poisoned_edges = torch.tensor(poisoned_edges, dtype=torch.long).t().contiguous()\n","    data.edge_index = torch.cat([edge_index, poisoned_edges], dim=1)\n","    return data, poisoned_edges\n","\n","# Backdoor Attack 3: Trigger-based Poisoning\n","def inject_trigger_attack(data, num_trigger_nodes=5, trigger_pattern=None):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_trigger_nodes)\n","    if trigger_pattern is None:\n","        trigger_pattern = torch.ones(data.num_node_features)\n","\n","    for node in poisoned_nodes:\n","        data.x[node] = trigger_pattern  # Set a specific trigger pattern in features\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","\n","    return data, poisoned_nodes\n","\n","# Filtration Method 1: Community Detection-Based Filtration\n","def community_detection_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    communities = nx.algorithms.community.greedy_modularity_communities(G)\n","    filtered_nodes = []\n","\n","    # Assuming smaller communities are potentially poisoned\n","    for community in communities:\n","        if len(community) < 10:  # Arbitrary threshold\n","            filtered_nodes.extend(list(community))\n","\n","    return filtered_nodes\n","\n","# Filtration Method 2: PCA Embedding-Based Detection\n","def pca_embedding_filter(data, n_components=2):\n","    X = data.x.cpu().detach().numpy()\n","    pca = PCA(n_components=n_components)\n","    X_pca = pca.fit_transform(X)\n","\n","    # Compute distances from the mean of embeddings\n","    distances = np.linalg.norm(X_pca - X_pca.mean(axis=0), axis=1)\n","    threshold = np.mean(distances) + 2 * np.std(distances)  # Arbitrary threshold\n","    filtered_nodes = np.where(distances > threshold)[0]\n","\n","    return filtered_nodes\n","\n","# Filtration Method 3: Spectral Analysis\n","def spectral_analysis_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    laplacian_matrix = nx.laplacian_matrix(G).toarray()\n","    eigenvalues = np.linalg.eigvals(laplacian_matrix)\n","\n","    # Identify anomalies by analyzing the spectrum of eigenvalues\n","    threshold = np.mean(eigenvalues) + 2 * np.std(eigenvalues)  # Arbitrary threshold\n","    filtered_nodes = [i for i, e in enumerate(eigenvalues) if e > threshold]\n","\n","    return filtered_nodes\n","\n","# Final Retraining after filtering poisoned nodes\n","def remove_filtered_nodes(data, filtered_nodes):\n","    data.train_mask[filtered_nodes] = False  # Remove poisoned nodes from training\n","    return data\n","\n","# Train on clean data\n","def run_clean_model():\n","    print(\"Training the model on clean data...\")\n","    data = original_data.clone().to(device)  # Reset to original clean data\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","    train(model, data)\n","    acc_clean = test(model, data)\n","    print(f\"Clean Accuracy: {acc_clean:.4f}\")\n","    return acc_clean\n","\n","# Function to execute one case\n","def run_case(attack_func, filter_func, attack_name, filter_name, num_poisoned):\n","    print(f\"\\n===== {attack_name} and {filter_name} Filtration =====\")\n","\n","    # Step 1: Reset to original clean data before attack\n","    data = original_data.clone().to(device)\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","\n","    # Step 2: Apply Backdoor Attack\n","    data, poisoned_nodes = attack_func(data, num_poisoned)\n","    print(f\"Training the model on poisoned data ({attack_name})...\")\n","    train(model, data)\n","    acc_poisoned = test(model, data)\n","    print(f\"Accuracy on poisoned data ({attack_name}): {acc_poisoned:.4f}\")\n","\n","    # Step 3: Apply Filtration\n","    filtered_nodes = filter_func(data)\n","    num_identified_backdoor = len(set(filtered_nodes) & set(poisoned_nodes))\n","    percent_removed = (num_identified_backdoor / len(poisoned_nodes)) * 100\n","\n","    print(f\"Backdoor Nodes Identified: {num_identified_backdoor}/{len(poisoned_nodes)}\")\n","    print(f\"Percentage of Backdoor Nodes Removed: {percent_removed:.2f}%\")\n","\n","    data = remove_filtered_nodes(data, filtered_nodes)\n","\n","    print(f\"Retraining the model after {filter_name} filtering...\")\n","    train(model, data)\n","    acc_defended = test(model, data)\n","    print(f\"Accuracy after {filter_name} filter ({attack_name}): {acc_defended:.4f}\")\n","    return acc_defended, num_identified_backdoor, percent_removed\n","\n","# Running all 9 cases\n","attacks = [(inject_feature_attack, \"Feature-based Attack\"),\n","           (inject_edge_attack, \"Edge-based Attack\"),\n","           (inject_trigger_attack, \"Trigger-based Attack\")]\n","\n","filters = [(community_detection_filter, \"Community Detection\"),\n","           (pca_embedding_filter, \"PCA Embedding\"),\n","           (spectral_analysis_filter, \"Spectral Analysis\")]\n","\n","# First, show the clean accuracy\n","clean_accuracy = run_clean_model()\n","\n","# Now, run all 9 combinations of attacks and filtrations\n","for attack_func, attack_name in attacks:\n","    for filter_func, filter_name in filters:\n","        run_case(attack_func, filter_func, attack_name, filter_name, num_poisoned=5)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128300,"status":"ok","timestamp":1729371841445,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"fK2Hyu5UhJ-A","outputId":"5104f544-67de-40df-8b91-4ce4f0ca808b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the model on clean data...\n","Clean Accuracy: 0.8040\n","\n","===== Feature-based Attack and Community Detection Filtration =====\n","Training the model on poisoned data (Feature-based Attack)...\n","Accuracy on poisoned data (Feature-based Attack): 0.8060\n","Backdoor Nodes Identified: 1/5\n","Percentage of Backdoor Nodes Removed: 20.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Feature-based Attack): 0.7880\n","\n","===== Feature-based Attack and PCA Embedding Filtration =====\n","Training the model on poisoned data (Feature-based Attack)...\n","Accuracy on poisoned data (Feature-based Attack): 0.7980\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Feature-based Attack): 0.7950\n","\n","===== Feature-based Attack and Spectral Analysis Filtration =====\n","Training the model on poisoned data (Feature-based Attack)...\n","Accuracy on poisoned data (Feature-based Attack): 0.8060\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Feature-based Attack): 0.5610\n","\n","===== Edge-based Attack and Community Detection Filtration =====\n","Training the model on poisoned data (Edge-based Attack)...\n","Accuracy on poisoned data (Edge-based Attack): 0.8070\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Edge-based Attack): 0.8020\n","\n","===== Edge-based Attack and PCA Embedding Filtration =====\n","Training the model on poisoned data (Edge-based Attack)...\n","Accuracy on poisoned data (Edge-based Attack): 0.7950\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Edge-based Attack): 0.7870\n","\n","===== Edge-based Attack and Spectral Analysis Filtration =====\n","Training the model on poisoned data (Edge-based Attack)...\n","Accuracy on poisoned data (Edge-based Attack): 0.7890\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Edge-based Attack): 0.5540\n","\n","===== Trigger-based Attack and Community Detection Filtration =====\n","Training the model on poisoned data (Trigger-based Attack)...\n","Accuracy on poisoned data (Trigger-based Attack): 0.8040\n","Backdoor Nodes Identified: 1/5\n","Percentage of Backdoor Nodes Removed: 20.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Trigger-based Attack): 0.7960\n","\n","===== Trigger-based Attack and PCA Embedding Filtration =====\n","Training the model on poisoned data (Trigger-based Attack)...\n","Accuracy on poisoned data (Trigger-based Attack): 0.7820\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Trigger-based Attack): 0.8010\n","\n","===== Trigger-based Attack and Spectral Analysis Filtration =====\n","Training the model on poisoned data (Trigger-based Attack)...\n","Accuracy on poisoned data (Trigger-based Attack): 0.7830\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Trigger-based Attack): 0.5530\n","\n","Optimal Policy: Accuracy = 0.7950, Backdoor Nodes Removed = 5\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import to_networkx, remove_self_loops\n","import random\n","import networkx as nx\n","from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define a simple GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(in_channels, 16)\n","        self.conv2 = GCNConv(16, out_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load data\n","original_data = dataset[0]  # Save the original dataset separately\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Train the GCN model\n","def train(model, data):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    model.train()\n","\n","    for epoch in range(200):\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the model\n","def test(model, data):\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n","    acc = int(correct) / int(data.test_mask.sum())\n","    return acc\n","\n","# Backdoor Attack 1: Feature-based Poisoning\n","def inject_feature_attack(data, num_poisoned_nodes=5):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_poisoned_nodes)\n","    for node in poisoned_nodes:\n","        data.x[node] = torch.rand_like(data.x[node])  # Randomize features as a trigger\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","    return data, poisoned_nodes\n","\n","# Backdoor Attack 2: Edge-based Poisoning\n","def inject_edge_attack(data, num_poisoned_edges=10):\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    poisoned_edges = []\n","    for _ in range(num_poisoned_edges):\n","        node1 = random.randint(0, data.num_nodes - 1)\n","        node2 = random.randint(0, data.num_nodes - 1)\n","        poisoned_edges.append([node1, node2])\n","    poisoned_edges = torch.tensor(poisoned_edges, dtype=torch.long).t().contiguous()\n","    data.edge_index = torch.cat([edge_index, poisoned_edges], dim=1)\n","    return data, poisoned_edges\n","\n","# Backdoor Attack 3: Trigger-based Poisoning\n","def inject_trigger_attack(data, num_trigger_nodes=5, trigger_pattern=None):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_trigger_nodes)\n","    if trigger_pattern is None:\n","        trigger_pattern = torch.ones(data.num_node_features)\n","\n","    for node in poisoned_nodes:\n","        data.x[node] = trigger_pattern  # Set a specific trigger pattern in features\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","\n","    return data, poisoned_nodes\n","\n","# Filtration Method 1: Community Detection-Based Filtration\n","def community_detection_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    communities = nx.algorithms.community.greedy_modularity_communities(G)\n","    filtered_nodes = []\n","\n","    # Assuming smaller communities are potentially poisoned\n","    for community in communities:\n","        if len(community) < 10:  # Arbitrary threshold\n","            filtered_nodes.extend(list(community))\n","\n","    return filtered_nodes\n","\n","# Filtration Method 2: PCA Embedding-Based Detection\n","def pca_embedding_filter(data, n_components=2):\n","    X = data.x.cpu().detach().numpy()\n","    pca = PCA(n_components=n_components)\n","    X_pca = pca.fit_transform(X)\n","\n","    # Compute distances from the mean of embeddings\n","    distances = np.linalg.norm(X_pca - X_pca.mean(axis=0), axis=1)\n","    threshold = np.mean(distances) + 2 * np.std(distances)  # Arbitrary threshold\n","    filtered_nodes = np.where(distances > threshold)[0]\n","\n","    return filtered_nodes\n","\n","# Filtration Method 3: Spectral Analysis\n","def spectral_analysis_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    laplacian_matrix = nx.laplacian_matrix(G).toarray()\n","    eigenvalues = np.linalg.eigvals(laplacian_matrix)\n","\n","    # Identify anomalies by analyzing the spectrum of eigenvalues\n","    threshold = np.mean(eigenvalues) + 2 * np.std(eigenvalues)  # Arbitrary threshold\n","    filtered_nodes = [i for i, e in enumerate(eigenvalues) if e > threshold]\n","\n","    return filtered_nodes\n","\n","# Final Retraining after filtering poisoned nodes\n","def remove_filtered_nodes(data, filtered_nodes):\n","    data.train_mask[filtered_nodes] = False  # Remove poisoned nodes from training\n","    return data\n","\n","# Train on clean data\n","def run_clean_model():\n","    print(\"Training the model on clean data...\")\n","    data = original_data.clone().to(device)  # Reset to original clean data\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","    train(model, data)\n","    acc_clean = test(model, data)\n","    print(f\"Clean Accuracy: {acc_clean:.4f}\")\n","    return acc_clean\n","\n","# Function to execute one case\n","def run_case(attack_func, filter_func, attack_name, filter_name, num_poisoned):\n","    print(f\"\\n===== {attack_name} and {filter_name} Filtration =====\")\n","\n","    # Step 1: Reset to original clean data before attack\n","    data = original_data.clone().to(device)\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","\n","    # Step 2: Apply Backdoor Attack\n","    data, poisoned_nodes = attack_func(data, num_poisoned)\n","    print(f\"Training the model on poisoned data ({attack_name})...\")\n","    train(model, data)\n","    acc_poisoned = test(model, data)\n","    print(f\"Accuracy on poisoned data ({attack_name}): {acc_poisoned:.4f}\")\n","\n","    # Step 3: Apply Filtration\n","    filtered_nodes = filter_func(data)\n","    num_identified_backdoor = len(set(filtered_nodes) & set(poisoned_nodes))\n","    percent_removed = (num_identified_backdoor / len(poisoned_nodes)) * 100\n","\n","    print(f\"Backdoor Nodes Identified: {num_identified_backdoor}/{len(poisoned_nodes)}\")\n","    print(f\"Percentage of Backdoor Nodes Removed: {percent_removed:.2f}%\")\n","\n","    data = remove_filtered_nodes(data, filtered_nodes)\n","\n","    print(f\"Retraining the model after {filter_name} filtering...\")\n","    train(model, data)\n","    acc_defended = test(model, data)\n","    print(f\"Accuracy after {filter_name} filter ({attack_name}): {acc_defended:.4f}\")\n","    return acc_defended, num_identified_backdoor, percent_removed\n","\n","# Function to select the optimal policy based on results\n","def select_optimal_policy(results):\n","    best_accuracy = 0\n","    best_policy = None\n","    best_removal = 0\n","\n","    for result in results:\n","        acc, removed_nodes, _ = result\n","        if acc > best_accuracy and removed_nodes > best_removal:\n","            best_accuracy = acc\n","            best_removal = removed_nodes\n","            best_policy = result\n","\n","    print(f\"\\nOptimal Policy: Accuracy = {best_policy[0]:.4f}, Backdoor Nodes Removed = {best_policy[1]}\")\n","    return best_policy\n","\n","# Running all attack and filter combinations\n","attacks = [(inject_feature_attack, \"Feature-based Attack\"),\n","           (inject_edge_attack, \"Edge-based Attack\"),\n","           (inject_trigger_attack, \"Trigger-based Attack\")]\n","\n","filters = [(community_detection_filter, \"Community Detection\"),\n","           (pca_embedding_filter, \"PCA Embedding\"),\n","           (spectral_analysis_filter, \"Spectral Analysis\")]\n","\n","# First, show the clean accuracy\n","clean_accuracy = run_clean_model()\n","\n","# Running the new attack and filter combinations and gathering results\n","results = []\n","for attack_func, attack_name in attacks:\n","    for filter_func, filter_name in filters:\n","        result = run_case(attack_func, filter_func, attack_name, filter_name, num_poisoned=5)\n","        results.append(result)\n","\n","# Select and display the optimal policy\n","optimal_policy = select_optimal_policy(results)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":246823,"status":"ok","timestamp":1729372507276,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"pLeQPnWVkWjs","outputId":"2173affb-d814-4344-8b03-84f922a02096"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the model on clean data...\n","Clean Accuracy: 0.8120\n","\n","===== Feature-based Attack, Node Feature Noise, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Feature-based Attack + Node Feature Noise): 0.7980\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Feature-based Attack + Node Feature Noise): 0.7820\n","\n","===== Feature-based Attack, Node Feature Noise, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Feature-based Attack + Node Feature Noise): 0.7740\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Feature-based Attack + Node Feature Noise): 0.7780\n","\n","===== Feature-based Attack, Node Feature Noise, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Feature-based Attack + Node Feature Noise): 0.7940\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Feature-based Attack + Node Feature Noise): 0.5550\n","\n","===== Feature-based Attack, Random Edge Dropout, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Feature-based Attack + Random Edge Dropout): 0.7990\n","Backdoor Nodes Identified: 1/5\n","Percentage of Backdoor Nodes Removed: 20.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Feature-based Attack + Random Edge Dropout): 0.7610\n","\n","===== Feature-based Attack, Random Edge Dropout, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Feature-based Attack + Random Edge Dropout): 0.7950\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Feature-based Attack + Random Edge Dropout): 0.8030\n","\n","===== Feature-based Attack, Random Edge Dropout, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Feature-based Attack + Random Edge Dropout): 0.7950\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Feature-based Attack + Random Edge Dropout): 0.5670\n","\n","===== Edge-based Attack, Node Feature Noise, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Edge-based Attack + Node Feature Noise): 0.7920\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Edge-based Attack + Node Feature Noise): 0.7750\n","\n","===== Edge-based Attack, Node Feature Noise, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Edge-based Attack + Node Feature Noise): 0.7630\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Edge-based Attack + Node Feature Noise): 0.7770\n","\n","===== Edge-based Attack, Node Feature Noise, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Edge-based Attack + Node Feature Noise): 0.7790\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Edge-based Attack + Node Feature Noise): 0.5580\n","\n","===== Edge-based Attack, Random Edge Dropout, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Edge-based Attack + Random Edge Dropout): 0.7870\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Edge-based Attack + Random Edge Dropout): 0.7730\n","\n","===== Edge-based Attack, Random Edge Dropout, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Edge-based Attack + Random Edge Dropout): 0.7950\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Edge-based Attack + Random Edge Dropout): 0.7900\n","\n","===== Edge-based Attack, Random Edge Dropout, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Edge-based Attack + Random Edge Dropout): 0.7910\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Edge-based Attack + Random Edge Dropout): 0.5600\n","\n","===== Trigger-based Attack, Node Feature Noise, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Trigger-based Attack + Node Feature Noise): 0.7710\n","Backdoor Nodes Identified: 1/5\n","Percentage of Backdoor Nodes Removed: 20.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Trigger-based Attack + Node Feature Noise): 0.7700\n","\n","===== Trigger-based Attack, Node Feature Noise, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Trigger-based Attack + Node Feature Noise): 0.8030\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Trigger-based Attack + Node Feature Noise): 0.8000\n","\n","===== Trigger-based Attack, Node Feature Noise, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Trigger-based Attack + Node Feature Noise): 0.7750\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Trigger-based Attack + Node Feature Noise): 0.5430\n","\n","===== Trigger-based Attack, Random Edge Dropout, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Trigger-based Attack + Random Edge Dropout): 0.7970\n","Backdoor Nodes Identified: 1/5\n","Percentage of Backdoor Nodes Removed: 20.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Trigger-based Attack + Random Edge Dropout): 0.7790\n","\n","===== Trigger-based Attack, Random Edge Dropout, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Trigger-based Attack + Random Edge Dropout): 0.7860\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Trigger-based Attack + Random Edge Dropout): 0.7930\n","\n","===== Trigger-based Attack, Random Edge Dropout, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Trigger-based Attack + Random Edge Dropout): 0.7820\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Trigger-based Attack + Random Edge Dropout): 0.5500\n","\n","Optimal Policy: Accuracy = 0.7780, Backdoor Nodes Removed = 5\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import to_networkx, remove_self_loops\n","import random\n","import networkx as nx\n","from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define a simple GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(in_channels, 16)\n","        self.conv2 = GCNConv(16, out_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load data\n","original_data = dataset[0]  # Save the original dataset separately\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Train the GCN model\n","def train(model, data):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    model.train()\n","\n","    for epoch in range(200):\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the model\n","def test(model, data):\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n","    acc = int(correct) / int(data.test_mask.sum())\n","    return acc\n","\n","# Backdoor Attack 1: Feature-based Poisoning\n","def inject_feature_attack(data, num_poisoned_nodes=5):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_poisoned_nodes)\n","    for node in poisoned_nodes:\n","        data.x[node] = torch.rand_like(data.x[node])  # Randomize features as a trigger\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","    return data, poisoned_nodes\n","\n","# Backdoor Attack 2: Edge-based Poisoning\n","def inject_edge_attack(data, num_poisoned_edges=10):\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    poisoned_edges = []\n","    for _ in range(num_poisoned_edges):\n","        node1 = random.randint(0, data.num_nodes - 1)\n","        node2 = random.randint(0, data.num_nodes - 1)\n","        poisoned_edges.append([node1, node2])\n","    poisoned_edges = torch.tensor(poisoned_edges, dtype=torch.long).t().contiguous()\n","    data.edge_index = torch.cat([edge_index, poisoned_edges], dim=1)\n","    return data, poisoned_edges\n","\n","# Backdoor Attack 3: Trigger-based Poisoning\n","def inject_trigger_attack(data, num_trigger_nodes=5, trigger_pattern=None):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_trigger_nodes)\n","    if trigger_pattern is None:\n","        trigger_pattern = torch.ones(data.num_node_features)\n","\n","    for node in poisoned_nodes:\n","        data.x[node] = trigger_pattern  # Set a specific trigger pattern in features\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","\n","    return data, poisoned_nodes\n","\n","# Augmentation Method 1: Node Feature Noise\n","def add_node_feature_noise(data, noise_level=0.1):\n","    noise = torch.randn_like(data.x) * noise_level\n","    data.x += noise  # Adding noise to node features\n","    return data\n","\n","# Augmentation Method 2: Random Edge Dropout\n","def random_edge_dropout(data, drop_prob=0.1):\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    num_edges = edge_index.size(1)\n","    drop_mask = torch.rand(num_edges) > drop_prob  # Drop edges with probability drop_prob\n","    data.edge_index = edge_index[:, drop_mask]\n","    return data\n","\n","# Filtration Method 1: Community Detection-Based Filtration\n","def community_detection_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    communities = nx.algorithms.community.greedy_modularity_communities(G)\n","    filtered_nodes = []\n","\n","    # Assuming smaller communities are potentially poisoned\n","    for community in communities:\n","        if len(community) < 10:  # Arbitrary threshold\n","            filtered_nodes.extend(list(community))\n","\n","    return filtered_nodes\n","\n","# Filtration Method 2: PCA Embedding-Based Detection\n","def pca_embedding_filter(data, n_components=2):\n","    X = data.x.cpu().detach().numpy()\n","    pca = PCA(n_components=n_components)\n","    X_pca = pca.fit_transform(X)\n","\n","    # Compute distances from the mean of embeddings\n","    distances = np.linalg.norm(X_pca - X_pca.mean(axis=0), axis=1)\n","    threshold = np.mean(distances) + 2 * np.std(distances)  # Arbitrary threshold\n","    filtered_nodes = np.where(distances > threshold)[0]\n","\n","    return filtered_nodes\n","\n","# Filtration Method 3: Spectral Analysis\n","def spectral_analysis_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    laplacian_matrix = nx.laplacian_matrix(G).toarray()\n","    eigenvalues = np.linalg.eigvals(laplacian_matrix)\n","\n","    # Identify anomalies by analyzing the spectrum of eigenvalues\n","    threshold = np.mean(eigenvalues) + 2 * np.std(eigenvalues)  # Arbitrary threshold\n","    filtered_nodes = [i for i, e in enumerate(eigenvalues) if e > threshold]\n","\n","    return filtered_nodes\n","\n","# Final Retraining after filtering poisoned nodes\n","def remove_filtered_nodes(data, filtered_nodes):\n","    data.train_mask[filtered_nodes] = False  # Remove poisoned nodes from training\n","    return data\n","\n","# Train on clean data\n","def run_clean_model():\n","    print(\"Training the model on clean data...\")\n","    data = original_data.clone().to(device)  # Reset to original clean data\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","    train(model, data)\n","    acc_clean = test(model, data)\n","    print(f\"Clean Accuracy: {acc_clean:.4f}\")\n","    return acc_clean\n","\n","# Function to execute one case with augmentation\n","def run_case(attack_func, augment_func, filter_func, attack_name, augment_name, filter_name, num_poisoned):\n","    print(f\"\\n===== {attack_name}, {augment_name}, and {filter_name} Filtration =====\")\n","\n","    # Step 1: Reset to original clean data before attack\n","    data = original_data.clone().to(device)\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","\n","    # Step 2: Apply Backdoor Attack\n","    data, poisoned_nodes = attack_func(data, num_poisoned)\n","\n","    # Step 3: Apply Augmentation\n","    data = augment_func(data)\n","\n","    print(f\"Training the model on poisoned and augmented data ({attack_name} + {augment_name})...\")\n","    train(model, data)\n","    acc_poisoned = test(model, data)\n","    print(f\"Accuracy on poisoned data ({attack_name} + {augment_name}): {acc_poisoned:.4f}\")\n","\n","    # Step 4: Apply Filtration\n","    filtered_nodes = filter_func(data)\n","    num_identified_backdoor = len(set(filtered_nodes) & set(poisoned_nodes))\n","    percent_removed = (num_identified_backdoor / len(poisoned_nodes)) * 100\n","\n","    print(f\"Backdoor Nodes Identified: {num_identified_backdoor}/{len(poisoned_nodes)}\")\n","    print(f\"Percentage of Backdoor Nodes Removed: {percent_removed:.2f}%\")\n","\n","    data = remove_filtered_nodes(data, filtered_nodes)\n","\n","    print(f\"Retraining the model after {filter_name} filtering...\")\n","    train(model, data)\n","    acc_defended = test(model, data)\n","    print(f\"Accuracy after {filter_name} filter ({attack_name} + {augment_name}): {acc_defended:.4f}\")\n","    return acc_defended, num_identified_backdoor, percent_removed\n","\n","# Function to select the optimal policy based on results\n","def select_optimal_policy(results):\n","    best_accuracy = 0\n","    best_policy = None\n","    best_removal = 0\n","\n","    for result in results:\n","        acc, removed_nodes, _ = result\n","        if acc > best_accuracy and removed_nodes > best_removal:\n","            best_accuracy = acc\n","            best_removal = removed_nodes\n","            best_policy = result\n","\n","    print(f\"\\nOptimal Policy: Accuracy = {best_policy[0]:.4f}, Backdoor Nodes Removed = {best_policy[1]}\")\n","    return best_policy\n","\n","# Running all attack, augmentation, and filter combinations\n","attacks = [(inject_feature_attack, \"Feature-based Attack\"),\n","           (inject_edge_attack, \"Edge-based Attack\"),\n","           (inject_trigger_attack, \"Trigger-based Attack\")]\n","\n","augmentations = [(add_node_feature_noise, \"Node Feature Noise\"),\n","                 (random_edge_dropout, \"Random Edge Dropout\")]\n","\n","filters = [(community_detection_filter, \"Community Detection\"),\n","           (pca_embedding_filter, \"PCA Embedding\"),\n","           (spectral_analysis_filter, \"Spectral Analysis\")]\n","\n","# First, show the clean accuracy\n","clean_accuracy = run_clean_model()\n","\n","# Running the new attack, augmentation, and filter combinations and gathering results\n","results = []\n","for attack_func, attack_name in attacks:\n","    for augment_func, augment_name in augmentations:\n","        for filter_func, filter_name in filters:\n","            result = run_case(attack_func, augment_func, filter_func, attack_name, augment_name, filter_name, num_poisoned=5)\n","            results.append(result)\n","\n","# Select and display the optimal policy\n","optimal_policy = select_optimal_policy(results)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255491,"status":"ok","timestamp":1729502837248,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"GNLT46vvnoMp","outputId":"b73b170b-1d75-4425-fa21-b2fc3df0b92b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the model on clean data...\n","Clean Accuracy: 0.7940\n","\n","===== Feature-based Attack, Node Feature Noise, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Feature-based Attack + Node Feature Noise): 0.7890\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Feature-based Attack + Node Feature Noise): 0.7830\n","\n","===== Feature-based Attack, Node Feature Noise, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Feature-based Attack + Node Feature Noise): 0.7890\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Feature-based Attack + Node Feature Noise): 0.7920\n","\n","===== Feature-based Attack, Node Feature Noise, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Feature-based Attack + Node Feature Noise): 0.7870\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Feature-based Attack + Node Feature Noise): 0.5470\n","\n","===== Feature-based Attack, Random Edge Dropout, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Feature-based Attack + Random Edge Dropout): 0.7830\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Feature-based Attack + Random Edge Dropout): 0.7840\n","\n","===== Feature-based Attack, Random Edge Dropout, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Feature-based Attack + Random Edge Dropout): 0.7950\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Feature-based Attack + Random Edge Dropout): 0.8020\n","\n","===== Feature-based Attack, Random Edge Dropout, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Feature-based Attack + Random Edge Dropout): 0.7890\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Feature-based Attack + Random Edge Dropout): 0.5690\n","\n","===== Edge-based Attack, Node Feature Noise, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Edge-based Attack + Node Feature Noise): 0.7760\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Edge-based Attack + Node Feature Noise): 0.7630\n","\n","===== Edge-based Attack, Node Feature Noise, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Edge-based Attack + Node Feature Noise): 0.7820\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Edge-based Attack + Node Feature Noise): 0.7660\n","\n","===== Edge-based Attack, Node Feature Noise, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Edge-based Attack + Node Feature Noise): 0.7890\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Edge-based Attack + Node Feature Noise): 0.5460\n","\n","===== Edge-based Attack, Random Edge Dropout, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Edge-based Attack + Random Edge Dropout): 0.7910\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Edge-based Attack + Random Edge Dropout): 0.7750\n","\n","===== Edge-based Attack, Random Edge Dropout, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Edge-based Attack + Random Edge Dropout): 0.7830\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Edge-based Attack + Random Edge Dropout): 0.7650\n","\n","===== Edge-based Attack, Random Edge Dropout, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Edge-based Attack + Random Edge Dropout): 0.7860\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Edge-based Attack + Random Edge Dropout): 0.5530\n","\n","===== Trigger-based Attack, Node Feature Noise, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Trigger-based Attack + Node Feature Noise): 0.7870\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Trigger-based Attack + Node Feature Noise): 0.7780\n","\n","===== Trigger-based Attack, Node Feature Noise, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Trigger-based Attack + Node Feature Noise): 0.7560\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Trigger-based Attack + Node Feature Noise): 0.7740\n","\n","===== Trigger-based Attack, Node Feature Noise, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Trigger-based Attack + Node Feature Noise): 0.8120\n","Backdoor Nodes Identified: 1/5\n","Percentage of Backdoor Nodes Removed: 20.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Trigger-based Attack + Node Feature Noise): 0.5440\n","\n","===== Trigger-based Attack, Random Edge Dropout, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Trigger-based Attack + Random Edge Dropout): 0.7830\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Trigger-based Attack + Random Edge Dropout): 0.7840\n","\n","===== Trigger-based Attack, Random Edge Dropout, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Trigger-based Attack + Random Edge Dropout): 0.7840\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Trigger-based Attack + Random Edge Dropout): 0.7940\n","\n","===== Trigger-based Attack, Random Edge Dropout, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Trigger-based Attack + Random Edge Dropout): 0.7820\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Trigger-based Attack + Random Edge Dropout): 0.5570\n","\n","Optimal Policy by Weighted Scoring: Accuracy = 0.8020, Backdoor Nodes Removed = 5, Weighted Score = 32.9010\n","\n","Pareto-optimal Policies: 1\n","Accuracy: 0.8020, Backdoor Nodes Removed: 5, Percentage Removed: 100.00%\n","Error: Mismatch between number of results (18) and costs (9).\n","\n","Optimal Policy after Robustness Check: Accuracy = 0.8020, Backdoor Nodes Removed = 5.0, Avg Percentage Removed: 100.00%\n","\n","Pareto-optimal Policies: 1\n","Accuracy: 0.8020, Backdoor Nodes Removed: 5, Percentage Removed: 100.00%\n","\n","Multi-objective Optimal Policy: Accuracy = 0.8020, Backdoor Nodes Removed = 5, Weighted Score = 2.4812\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import to_networkx, remove_self_loops\n","import random\n","import networkx as nx\n","from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define a simple GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(in_channels, 16)\n","        self.conv2 = GCNConv(16, out_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load data\n","original_data = dataset[0]  # Save the original dataset separately\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Train the GCN model\n","def train(model, data):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    model.train()\n","\n","    for epoch in range(200):\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the model\n","def test(model, data):\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n","    acc = int(correct) / int(data.test_mask.sum())\n","    return acc\n","\n","# Backdoor Attack 1: Feature-based Poisoning\n","def inject_feature_attack(data, num_poisoned_nodes=5):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_poisoned_nodes)\n","    for node in poisoned_nodes:\n","        data.x[node] = torch.rand_like(data.x[node])  # Randomize features as a trigger\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","    return data, poisoned_nodes\n","\n","# Backdoor Attack 2: Edge-based Poisoning\n","def inject_edge_attack(data, num_poisoned_edges=10):\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    poisoned_edges = []\n","    for _ in range(num_poisoned_edges):\n","        node1 = random.randint(0, data.num_nodes - 1)\n","        node2 = random.randint(0, data.num_nodes - 1)\n","        poisoned_edges.append([node1, node2])\n","    poisoned_edges = torch.tensor(poisoned_edges, dtype=torch.long).t().contiguous()\n","    data.edge_index = torch.cat([edge_index, poisoned_edges], dim=1)\n","    return data, poisoned_edges\n","\n","# Backdoor Attack 3: Trigger-based Poisoning\n","def inject_trigger_attack(data, num_trigger_nodes=5, trigger_pattern=None):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_trigger_nodes)\n","    if trigger_pattern is None:\n","        trigger_pattern = torch.ones(data.num_node_features)\n","\n","    for node in poisoned_nodes:\n","        data.x[node] = trigger_pattern  # Set a specific trigger pattern in features\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","\n","    return data, poisoned_nodes\n","\n","# Augmentation Method 1: Node Feature Noise\n","def add_node_feature_noise(data, noise_level=0.1):\n","    noise = torch.randn_like(data.x) * noise_level\n","    data.x += noise  # Adding noise to node features\n","    return data\n","\n","# Augmentation Method 2: Random Edge Dropout\n","def random_edge_dropout(data, drop_prob=0.1):\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    num_edges = edge_index.size(1)\n","    drop_mask = torch.rand(num_edges) > drop_prob  # Drop edges with probability drop_prob\n","    data.edge_index = edge_index[:, drop_mask]\n","    return data\n","\n","# Filtration Method 1: Community Detection-Based Filtration\n","def community_detection_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    communities = nx.algorithms.community.greedy_modularity_communities(G)\n","    filtered_nodes = []\n","\n","    # Assuming smaller communities are potentially poisoned\n","    for community in communities:\n","        if len(community) < 10:  # Arbitrary threshold\n","            filtered_nodes.extend(list(community))\n","\n","    return filtered_nodes\n","\n","# Filtration Method 2: PCA Embedding-Based Detection\n","def pca_embedding_filter(data, n_components=2):\n","    X = data.x.cpu().detach().numpy()\n","    pca = PCA(n_components=n_components)\n","    X_pca = pca.fit_transform(X)\n","\n","    # Compute distances from the mean of embeddings\n","    distances = np.linalg.norm(X_pca - X_pca.mean(axis=0), axis=1)\n","    threshold = np.mean(distances) + 2 * np.std(distances)  # Arbitrary threshold\n","    filtered_nodes = np.where(distances > threshold)[0]\n","\n","    return filtered_nodes\n","\n","# Filtration Method 3: Spectral Analysis\n","def spectral_analysis_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    laplacian_matrix = nx.laplacian_matrix(G).toarray()\n","    eigenvalues = np.linalg.eigvals(laplacian_matrix)\n","\n","    # Identify anomalies by analyzing the spectrum of eigenvalues\n","    threshold = np.mean(eigenvalues) + 2 * np.std(eigenvalues)  # Arbitrary threshold\n","    filtered_nodes = [i for i, e in enumerate(eigenvalues) if e > threshold]\n","\n","    return filtered_nodes\n","\n","# Final Retraining after filtering poisoned nodes\n","def remove_filtered_nodes(data, filtered_nodes):\n","    data.train_mask[filtered_nodes] = False  # Remove poisoned nodes from training\n","    return data\n","\n","# Train on clean data\n","def run_clean_model():\n","    print(\"Training the model on clean data...\")\n","    data = original_data.clone().to(device)  # Reset to original clean data\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","    train(model, data)\n","    acc_clean = test(model, data)\n","    print(f\"Clean Accuracy: {acc_clean:.4f}\")\n","    return acc_clean\n","\n","# Function to execute one case with augmentation\n","def run_case(attack_func, augment_func, filter_func, attack_name, augment_name, filter_name, num_poisoned):\n","    print(f\"\\n===== {attack_name}, {augment_name}, and {filter_name} Filtration =====\")\n","\n","    # Step 1: Reset to original clean data before attack\n","    data = original_data.clone().to(device)\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","\n","    # Step 2: Apply Backdoor Attack\n","    data, poisoned_nodes = attack_func(data, num_poisoned)\n","\n","    # Step 3: Apply Augmentation\n","    data = augment_func(data)\n","\n","    print(f\"Training the model on poisoned and augmented data ({attack_name} + {augment_name})...\")\n","    train(model, data)\n","    acc_poisoned = test(model, data)\n","    print(f\"Accuracy on poisoned data ({attack_name} + {augment_name}): {acc_poisoned:.4f}\")\n","\n","    # Step 4: Apply Filtration\n","    filtered_nodes = filter_func(data)\n","    num_identified_backdoor = len(set(filtered_nodes) & set(poisoned_nodes))\n","    percent_removed = (num_identified_backdoor / len(poisoned_nodes)) * 100\n","\n","    print(f\"Backdoor Nodes Identified: {num_identified_backdoor}/{len(poisoned_nodes)}\")\n","    print(f\"Percentage of Backdoor Nodes Removed: {percent_removed:.2f}%\")\n","\n","    data = remove_filtered_nodes(data, filtered_nodes)\n","\n","    print(f\"Retraining the model after {filter_name} filtering...\")\n","    train(model, data)\n","    acc_defended = test(model, data)\n","    print(f\"Accuracy after {filter_name} filter ({attack_name} + {augment_name}): {acc_defended:.4f}\")\n","    return acc_defended, num_identified_backdoor, percent_removed\n","\n","# Weighted Scoring Method\n","def weighted_scoring(results, accuracy_weight=0.5, removal_weight=0.5, percentage_weight=0.3):\n","    best_score = 0\n","    best_policy = None\n","\n","    for result in results:\n","        acc, removed_nodes, percent_removed = result\n","        score = (accuracy_weight * acc) + (removal_weight * removed_nodes) + (percentage_weight * percent_removed)\n","\n","        if score > best_score:\n","            best_score = score\n","            best_policy = result\n","\n","    print(f\"\\nOptimal Policy by Weighted Scoring: Accuracy = {best_policy[0]:.4f}, Backdoor Nodes Removed = {best_policy[1]}, Weighted Score = {best_score:.4f}\")\n","    return best_policy\n","\n","# Pareto Efficiency\n","def pareto_optimal_selection(results):\n","    pareto_optimal = []\n","\n","    for i, result in enumerate(results):\n","        dominated = False\n","        for j, other in enumerate(results):\n","            if i != j and all([other[k] >= result[k] for k in range(3)]) and any([other[k] > result[k] for k in range(3)]):\n","                dominated = True\n","                break\n","        if not dominated:\n","            pareto_optimal.append(result)\n","\n","    print(f\"\\nPareto-optimal Policies: {len(pareto_optimal)}\")\n","    for policy in pareto_optimal:\n","        print(f\"Accuracy: {policy[0]:.4f}, Backdoor Nodes Removed: {policy[1]}, Percentage Removed: {policy[2]:.2f}%\")\n","\n","    return pareto_optimal\n","\n","# Cost-Benefit Analysis\n","def cost_benefit_analysis(results, costs):\n","    if len(costs) != len(results):\n","        print(f\"Error: Mismatch between number of results ({len(results)}) and costs ({len(costs)}).\")\n","        return None\n","\n","    best_benefit_cost_ratio = 0\n","    best_policy = None\n","\n","    for i, result in enumerate(results):\n","        acc, removed_nodes, percent_removed = result\n","        cost = costs[i]\n","\n","        benefit_cost_ratio = acc / cost\n","\n","        if benefit_cost_ratio > best_benefit_cost_ratio:\n","            best_benefit_cost_ratio = benefit_cost_ratio\n","            best_policy = result\n","\n","    print(f\"\\nOptimal Policy by Cost-Benefit Analysis: Accuracy = {best_policy[0]:.4f}, Backdoor Nodes Removed = {best_policy[1]}, Benefit-Cost Ratio = {best_benefit_cost_ratio:.4f}\")\n","    return best_policy\n","\n","# Robustness Check\n","def robustness_check(results, n_runs=5):\n","    averaged_results = []\n","\n","    for result in results:\n","        total_acc, total_removed_nodes, total_percent_removed = 0, 0, 0\n","        for _ in range(n_runs):\n","            acc, removed_nodes, percent_removed = result  # You'd need to re-run the experiments here in a real scenario\n","            total_acc += acc\n","            total_removed_nodes += removed_nodes\n","            total_percent_removed += percent_removed\n","\n","        avg_acc = total_acc / n_runs\n","        avg_removed_nodes = total_removed_nodes / n_runs\n","        avg_percent_removed = total_percent_removed / n_runs\n","        averaged_results.append((avg_acc, avg_removed_nodes, avg_percent_removed))\n","\n","    best_result = max(averaged_results, key=lambda x: x[0])  # Select based on accuracy\n","    print(f\"\\nOptimal Policy after Robustness Check: Accuracy = {best_result[0]:.4f}, Backdoor Nodes Removed = {best_result[1]}, Avg Percentage Removed: {best_result[2]:.2f}%\")\n","    return best_result\n","\n","# Multi-Objective Optimization\n","def multi_objective_optimization(results, accuracy_weight=0.6, removal_weight=0.4):\n","    pareto_optimal = pareto_optimal_selection(results)\n","\n","    best_score = 0\n","    best_policy = None\n","\n","    for result in pareto_optimal:\n","        acc, removed_nodes, _ = result\n","        score = (accuracy_weight * acc) + (removal_weight * removed_nodes)\n","\n","        if score > best_score:\n","            best_score = score\n","            best_policy = result\n","\n","    print(f\"\\nMulti-objective Optimal Policy: Accuracy = {best_policy[0]:.4f}, Backdoor Nodes Removed = {best_policy[1]}, Weighted Score = {best_score:.4f}\")\n","    return best_policy\n","\n","# Running all attack, augmentation, and filter combinations\n","attacks = [(inject_feature_attack, \"Feature-based Attack\"),\n","           (inject_edge_attack, \"Edge-based Attack\"),\n","           (inject_trigger_attack, \"Trigger-based Attack\")]\n","\n","augmentations = [(add_node_feature_noise, \"Node Feature Noise\"),\n","                 (random_edge_dropout, \"Random Edge Dropout\")]\n","\n","filters = [(community_detection_filter, \"Community Detection\"),\n","           (pca_embedding_filter, \"PCA Embedding\"),\n","           (spectral_analysis_filter, \"Spectral Analysis\")]\n","\n","# First, show the clean accuracy\n","clean_accuracy = run_clean_model()\n","\n","# Running the new attack, augmentation, and filter combinations and gathering results\n","results = []\n","for attack_func, attack_name in attacks:\n","    for augment_func, augment_name in augmentations:\n","        for filter_func, filter_name in filters:\n","            result = run_case(attack_func, augment_func, filter_func, attack_name, augment_name, filter_name, num_poisoned=5)\n","            results.append(result)\n","\n","# Example Costs for Cost-Benefit Analysis\n","costs = [1, 2, 3, 1, 2, 3, 1, 2, 3]  # Make sure this matches the number of attack + augment + filter combinations\n","\n","# Select and display the optimal policy using different techniques\n","optimal_weighted = weighted_scoring(results)\n","optimal_pareto = pareto_optimal_selection(results)\n","optimal_cost_benefit = cost_benefit_analysis(results, costs)\n","optimal_robustness = robustness_check(results)\n","optimal_multi_objective = multi_objective_optimization(results)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259152,"status":"ok","timestamp":1729503275002,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"Pw3JyfEqJb9W","outputId":"b8c04b5e-689c-4f6d-840e-03c8bff48b33"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the model on clean data...\n","Clean Accuracy: 0.8040\n","\n","===== Feature-based Attack, Node Feature Noise, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Feature-based Attack + Node Feature Noise): 0.7720\n","Attack Success Rate: 0.0398\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Feature-based Attack + Node Feature Noise): 0.7730\n","\n","===== Feature-based Attack, Node Feature Noise, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Feature-based Attack + Node Feature Noise): 0.7920\n","Attack Success Rate: 0.0149\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Feature-based Attack + Node Feature Noise): 0.7940\n","\n","===== Feature-based Attack, Node Feature Noise, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Feature-based Attack + Node Feature Noise): 0.7720\n","Attack Success Rate: 0.0398\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Feature-based Attack + Node Feature Noise): 0.5460\n","\n","===== Feature-based Attack, Random Edge Dropout, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Feature-based Attack + Random Edge Dropout): 0.7950\n","Attack Success Rate: 0.0112\n","Backdoor Nodes Identified: 1/5\n","Percentage of Backdoor Nodes Removed: 20.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Feature-based Attack + Random Edge Dropout): 0.7840\n","\n","===== Feature-based Attack, Random Edge Dropout, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Feature-based Attack + Random Edge Dropout): 0.7950\n","Attack Success Rate: 0.0112\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Feature-based Attack + Random Edge Dropout): 0.7960\n","\n","===== Feature-based Attack, Random Edge Dropout, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Feature-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Feature-based Attack + Random Edge Dropout): 0.7820\n","Attack Success Rate: 0.0274\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Feature-based Attack + Random Edge Dropout): 0.5460\n","\n","===== Edge-based Attack, Node Feature Noise, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Edge-based Attack + Node Feature Noise): 0.7830\n","Attack Success Rate: 0.0261\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Edge-based Attack + Node Feature Noise): 0.7910\n","\n","===== Edge-based Attack, Node Feature Noise, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Edge-based Attack + Node Feature Noise): 0.7910\n","Attack Success Rate: 0.0162\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Edge-based Attack + Node Feature Noise): 0.7940\n","\n","===== Edge-based Attack, Node Feature Noise, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Edge-based Attack + Node Feature Noise): 0.7690\n","Attack Success Rate: 0.0435\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Edge-based Attack + Node Feature Noise): 0.5490\n","\n","===== Edge-based Attack, Random Edge Dropout, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Edge-based Attack + Random Edge Dropout): 0.7850\n","Attack Success Rate: 0.0236\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Edge-based Attack + Random Edge Dropout): 0.7800\n","\n","===== Edge-based Attack, Random Edge Dropout, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Edge-based Attack + Random Edge Dropout): 0.7920\n","Attack Success Rate: 0.0149\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Edge-based Attack + Random Edge Dropout): 0.7640\n","\n","===== Edge-based Attack, Random Edge Dropout, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Edge-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Edge-based Attack + Random Edge Dropout): 0.7890\n","Attack Success Rate: 0.0187\n","Backdoor Nodes Identified: 0/2\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Edge-based Attack + Random Edge Dropout): 0.5680\n","\n","===== Trigger-based Attack, Node Feature Noise, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Trigger-based Attack + Node Feature Noise): 0.7920\n","Attack Success Rate: 0.0149\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Trigger-based Attack + Node Feature Noise): 0.7660\n","\n","===== Trigger-based Attack, Node Feature Noise, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Trigger-based Attack + Node Feature Noise): 0.7860\n","Attack Success Rate: 0.0224\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Trigger-based Attack + Node Feature Noise): 0.7900\n","\n","===== Trigger-based Attack, Node Feature Noise, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Node Feature Noise)...\n","Accuracy on poisoned data (Trigger-based Attack + Node Feature Noise): 0.7490\n","Attack Success Rate: 0.0684\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Trigger-based Attack + Node Feature Noise): 0.5220\n","\n","===== Trigger-based Attack, Random Edge Dropout, and Community Detection Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Trigger-based Attack + Random Edge Dropout): 0.7860\n","Attack Success Rate: 0.0224\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Community Detection filtering...\n","Accuracy after Community Detection filter (Trigger-based Attack + Random Edge Dropout): 0.7730\n","\n","===== Trigger-based Attack, Random Edge Dropout, and PCA Embedding Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Trigger-based Attack + Random Edge Dropout): 0.7820\n","Attack Success Rate: 0.0274\n","Backdoor Nodes Identified: 5/5\n","Percentage of Backdoor Nodes Removed: 100.00%\n","Retraining the model after PCA Embedding filtering...\n","Accuracy after PCA Embedding filter (Trigger-based Attack + Random Edge Dropout): 0.7990\n","\n","===== Trigger-based Attack, Random Edge Dropout, and Spectral Analysis Filtration =====\n","Training the model on poisoned and augmented data (Trigger-based Attack + Random Edge Dropout)...\n","Accuracy on poisoned data (Trigger-based Attack + Random Edge Dropout): 0.7660\n","Attack Success Rate: 0.0473\n","Backdoor Nodes Identified: 0/5\n","Percentage of Backdoor Nodes Removed: 0.00%\n","Retraining the model after Spectral Analysis filtering...\n","Accuracy after Spectral Analysis filter (Trigger-based Attack + Random Edge Dropout): 0.5490\n","\n","Optimal Policy by Weighted Scoring: Accuracy = 0.7990, Backdoor Nodes Removed = 5, Weighted Score = 32.9050\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import to_networkx, remove_self_loops\n","import random\n","import networkx as nx\n","from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define a simple GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(in_channels, 16)\n","        self.conv2 = GCNConv(16, out_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Load data\n","original_data = dataset[0]  # Save the original dataset separately\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Train the GCN model\n","def train(model, data):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    model.train()\n","\n","    for epoch in range(200):\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the model\n","def test(model, data):\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n","    acc = int(correct) / int(data.test_mask.sum())\n","    return acc\n","\n","# Backdoor Attack 1: Feature-based Poisoning\n","def inject_feature_attack(data, num_poisoned_nodes=5):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_poisoned_nodes)\n","    for node in poisoned_nodes:\n","        data.x[node] = torch.rand_like(data.x[node])  # Randomize features as a trigger\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","    return data, poisoned_nodes\n","\n","# Backdoor Attack 2: Edge-based Poisoning\n","def inject_edge_attack(data, num_poisoned_edges=10):\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    poisoned_edges = []\n","    for _ in range(num_poisoned_edges):\n","        node1 = random.randint(0, data.num_nodes - 1)\n","        node2 = random.randint(0, data.num_nodes - 1)\n","        poisoned_edges.append([node1, node2])\n","    poisoned_edges = torch.tensor(poisoned_edges, dtype=torch.long).t().contiguous()\n","    data.edge_index = torch.cat([edge_index, poisoned_edges], dim=1)\n","    return data, poisoned_edges\n","\n","# Backdoor Attack 3: Trigger-based Poisoning\n","def inject_trigger_attack(data, num_trigger_nodes=5, trigger_pattern=None):\n","    poisoned_nodes = random.sample(range(data.num_nodes), num_trigger_nodes)\n","    if trigger_pattern is None:\n","        trigger_pattern = torch.ones(data.num_node_features)\n","\n","    for node in poisoned_nodes:\n","        data.x[node] = trigger_pattern  # Set a specific trigger pattern in features\n","        data.y[node] = random.randint(0, dataset.num_classes - 1)  # Mislabel\n","\n","    return data, poisoned_nodes\n","\n","# Augmentation Method 1: Node Feature Noise\n","def add_node_feature_noise(data, noise_level=0.1):\n","    noise = torch.randn_like(data.x) * noise_level\n","    data.x += noise  # Adding noise to node features\n","    return data\n","\n","# Augmentation Method 2: Random Edge Dropout\n","def random_edge_dropout(data, drop_prob=0.1):\n","    edge_index, _ = remove_self_loops(data.edge_index)\n","    num_edges = edge_index.size(1)\n","    drop_mask = torch.rand(num_edges) > drop_prob  # Drop edges with probability drop_prob\n","    data.edge_index = edge_index[:, drop_mask]\n","    return data\n","\n","# Filtration Method 1: Community Detection-Based Filtration\n","def community_detection_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    communities = nx.algorithms.community.greedy_modularity_communities(G)\n","    filtered_nodes = []\n","\n","    # Assuming smaller communities are potentially poisoned\n","    for community in communities:\n","        if len(community) < 10:  # Arbitrary threshold\n","            filtered_nodes.extend(list(community))\n","\n","    return filtered_nodes\n","\n","# Filtration Method 2: PCA Embedding-Based Detection\n","def pca_embedding_filter(data, n_components=2):\n","    X = data.x.cpu().detach().numpy()\n","    pca = PCA(n_components=n_components)\n","    X_pca = pca.fit_transform(X)\n","\n","    # Compute distances from the mean of embeddings\n","    distances = np.linalg.norm(X_pca - X_pca.mean(axis=0), axis=1)\n","    threshold = np.mean(distances) + 2 * np.std(distances)  # Arbitrary threshold\n","    filtered_nodes = np.where(distances > threshold)[0]\n","\n","    return filtered_nodes\n","\n","# Filtration Method 3: Spectral Analysis\n","def spectral_analysis_filter(data):\n","    G = to_networkx(data, to_undirected=True)\n","    laplacian_matrix = nx.laplacian_matrix(G).toarray()\n","    eigenvalues = np.linalg.eigvals(laplacian_matrix)\n","\n","    # Identify anomalies by analyzing the spectrum of eigenvalues\n","    threshold = np.mean(eigenvalues) + 2 * np.std(eigenvalues)  # Arbitrary threshold\n","    filtered_nodes = [i for i, e in enumerate(eigenvalues) if e > threshold]\n","\n","    return filtered_nodes\n","\n","# Final Retraining after filtering poisoned nodes\n","def remove_filtered_nodes(data, filtered_nodes):\n","    data.train_mask[filtered_nodes] = False  # Remove poisoned nodes from training\n","    return data\n","\n","# Train on clean data\n","def run_clean_model():\n","    print(\"Training the model on clean data...\")\n","    data = original_data.clone().to(device)  # Reset to original clean data\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","    train(model, data)\n","    acc_clean = test(model, data)\n","    print(f\"Clean Accuracy: {acc_clean:.4f}\")\n","    return acc_clean\n","\n","# Function to execute one case with augmentation\n","def run_case(attack_func, augment_func, filter_func, attack_name, augment_name, filter_name, num_poisoned, acc_clean):\n","    print(f\"\\n===== {attack_name}, {augment_name}, and {filter_name} Filtration =====\")\n","\n","    # Step 1: Reset to original clean data before attack\n","    data = original_data.clone().to(device)\n","    model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n","\n","    # Step 2: Apply Backdoor Attack\n","    data, poisoned_nodes = attack_func(data, num_poisoned)\n","\n","    # Step 3: Apply Augmentation\n","    data = augment_func(data)\n","\n","    print(f\"Training the model on poisoned and augmented data ({attack_name} + {augment_name})...\")\n","    train(model, data)\n","    acc_poisoned = test(model, data)\n","    print(f\"Accuracy on poisoned data ({attack_name} + {augment_name}): {acc_poisoned:.4f}\")\n","\n","    # Calculate Attack Success Rate (ASR)\n","    attack_success_rate = 1 - (acc_poisoned / acc_clean)\n","    print(f\"Attack Success Rate: {attack_success_rate:.4f}\")\n","\n","    # Step 4: Apply Filtration\n","    filtered_nodes = filter_func(data)\n","    num_identified_backdoor = len(set(filtered_nodes) & set(poisoned_nodes))\n","    percent_removed = (num_identified_backdoor / len(poisoned_nodes)) * 100\n","\n","    print(f\"Backdoor Nodes Identified: {num_identified_backdoor}/{len(poisoned_nodes)}\")\n","    print(f\"Percentage of Backdoor Nodes Removed: {percent_removed:.2f}%\")\n","\n","    data = remove_filtered_nodes(data, filtered_nodes)\n","\n","    print(f\"Retraining the model after {filter_name} filtering...\")\n","    train(model, data)\n","    acc_defended = test(model, data)\n","    print(f\"Accuracy after {filter_name} filter ({attack_name} + {augment_name}): {acc_defended:.4f}\")\n","\n","    return acc_defended, num_identified_backdoor, percent_removed, attack_success_rate\n","\n","# Weighted Scoring Method\n","def weighted_scoring(results, accuracy_weight=0.5, removal_weight=0.5, percentage_weight=0.3, asr_weight=0.2):\n","    best_score = 0\n","    best_policy = None\n","\n","    for result in results:\n","        acc, removed_nodes, percent_removed, asr = result\n","        score = (accuracy_weight * acc) + (removal_weight * removed_nodes) + (percentage_weight * percent_removed) + (asr_weight * asr)\n","\n","        if score > best_score:\n","            best_score = score\n","            best_policy = result\n","\n","    print(f\"\\nOptimal Policy by Weighted Scoring: Accuracy = {best_policy[0]:.4f}, Backdoor Nodes Removed = {best_policy[1]}, Weighted Score = {best_score:.4f}\")\n","    return best_policy\n","\n","# Running all attack, augmentation, and filter combinations\n","attacks = [(inject_feature_attack, \"Feature-based Attack\"),\n","           (inject_edge_attack, \"Edge-based Attack\"),\n","           (inject_trigger_attack, \"Trigger-based Attack\")]\n","\n","augmentations = [(add_node_feature_noise, \"Node Feature Noise\"),\n","                 (random_edge_dropout, \"Random Edge Dropout\")]\n","\n","filters = [(community_detection_filter, \"Community Detection\"),\n","           (pca_embedding_filter, \"PCA Embedding\"),\n","           (spectral_analysis_filter, \"Spectral Analysis\")]\n","\n","# First, show the clean accuracy\n","clean_accuracy = run_clean_model()\n","\n","# Running the new attack, augmentation, and filter combinations and gathering results\n","results = []\n","for attack_func, attack_name in attacks:\n","    for augment_func, augment_name in augmentations:\n","        for filter_func, filter_name in filters:\n","            result = run_case(attack_func, augment_func, filter_func, attack_name, augment_name, filter_name, num_poisoned=5, acc_clean=clean_accuracy)\n","            results.append(result)\n","\n","# Example of Weighted Scoring\n","optimal_weighted = weighted_scoring(results)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08srFvVpu3PM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1730025376730,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"Zn5JgzEff-8x","outputId":"5fe96382-c514-408f-a2a2-b134c15fd715"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n","Processing...\n","Done!\n"]},{"name":"stdout","output_type":"stream","text":["Clean Test Accuracy: 0.7870\n","Subgraph Attack Test Accuracy: 0.7930\n","Accuracy Drop: -0.0060\n","Feature Attack Test Accuracy: 0.7900\n","Accuracy Drop: -0.0030\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","import copy\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define the GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, input_features, hidden_dim, num_classes):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(input_features, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","# Function to train the model\n","def train(model, data, optimizer):\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test(model, data):\n","    model.eval()\n","    logits = model(data)\n","    accs = []\n","    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n","        pred = logits[mask].argmax(dim=1)\n","        acc = (pred == data.y[mask]).sum().item() / mask.sum().item()\n","        accs.append(acc)\n","    return accs\n","\n","# Prepare data\n","data = dataset[0]\n","input_features = dataset.num_node_features\n","hidden_dim = 16\n","num_classes = dataset.num_classes\n","\n","# Train on clean data\n","clean_model = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(clean_model.parameters(), lr=0.01, weight_decay=5e-4)\n","\n","for epoch in range(200):\n","    train(clean_model, data, optimizer)\n","\n","clean_train_acc, clean_val_acc, clean_test_acc = test(clean_model, data)\n","print(f'Clean Test Accuracy: {clean_test_acc:.4f}')\n","\n","# Helper function to inject backdoor\n","def inject_subgraph_trigger(data, trigger_nodes, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    num_nodes = data.num_nodes\n","\n","    # Add edges to form a triangular subgraph (trigger)\n","    poisoned_data.edge_index = torch.cat([\n","        poisoned_data.edge_index,\n","        torch.tensor([[trigger_nodes[0], trigger_nodes[1]],\n","                      [trigger_nodes[1], trigger_nodes[2]],\n","                      [trigger_nodes[2], trigger_nodes[0]]], dtype=torch.long).t()\n","    ], dim=1)\n","\n","    # Assign the target class to the poisoned nodes\n","    poisoned_data.y[trigger_nodes] = target_class\n","    return poisoned_data\n","\n","def inject_feature_trigger(data, trigger_nodes, feature_dim, trigger_value, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Modify features to include trigger\n","    poisoned_data.x[trigger_nodes, feature_dim] = trigger_value\n","    # Assign the target class to the poisoned nodes\n","    poisoned_data.y[trigger_nodes] = target_class\n","    return poisoned_data\n","\n","# Attack 1: Subgraph-Based Backdoor Attack\n","trigger_nodes = [0, 1, 2]  # Nodes to modify\n","target_class = data.y.max().item()  # Use the maximum class label as the target\n","\n","poisoned_data_subgraph = inject_subgraph_trigger(data, trigger_nodes, target_class)\n","\n","# Retrain the model on poisoned data\n","model_subgraph = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(model_subgraph.parameters(), lr=0.01, weight_decay=5e-4)\n","\n","for epoch in range(200):\n","    train(model_subgraph, poisoned_data_subgraph, optimizer)\n","\n","subgraph_train_acc, subgraph_val_acc, subgraph_test_acc = test(model_subgraph, poisoned_data_subgraph)\n","print(f'Subgraph Attack Test Accuracy: {subgraph_test_acc:.4f}')\n","print(f'Accuracy Drop: {clean_test_acc - subgraph_test_acc:.4f}')\n","\n","# Attack 2: Feature-Based Backdoor Attack\n","feature_dim = 0  # Feature dimension to modify\n","trigger_value = data.x[:, feature_dim].max() + 10  # Set a high value as trigger\n","\n","poisoned_data_feature = inject_feature_trigger(data, trigger_nodes, feature_dim, trigger_value, target_class)\n","\n","# Retrain the model on poisoned data\n","model_feature = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(model_feature.parameters(), lr=0.01, weight_decay=5e-4)\n","\n","for epoch in range(200):\n","    train(model_feature, poisoned_data_feature, optimizer)\n","\n","feature_train_acc, feature_val_acc, feature_test_acc = test(model_feature, poisoned_data_feature)\n","print(f'Feature Attack Test Accuracy: {feature_test_acc:.4f}')\n","print(f'Accuracy Drop: {clean_test_acc - feature_test_acc:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44125,"status":"ok","timestamp":1730025505083,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"DaiIh5T0i97M","outputId":"83c354db-333e-409a-b48f-8bee9fc47b02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Clean Test Accuracy: 0.8070\n","Attack 1: Subgraph-Based Backdoor Attack\n","Subgraph Attack Test Accuracy: 0.7910\n","Accuracy Drop: 0.0160\n","\n","Attack 2: Feature-Based Backdoor Attack\n","Feature Attack Test Accuracy: 0.8040\n","Accuracy Drop: 0.0030\n","\n","Attack 3: Edge Manipulation Backdoor Attack\n","Edge Manipulation Attack Test Accuracy: 0.7880\n","Accuracy Drop: 0.0190\n","\n","Attack 4: Global Trigger Backdoor Attack\n","Global Trigger Attack Test Accuracy: 1.0000\n","Accuracy Drop: -0.1930\n","\n","Attack 5: Local Trigger Backdoor Attack\n","Local Trigger Attack Test Accuracy: 0.7840\n","Accuracy Drop: 0.0230\n","\n","Attack 6: Label-Consistent Backdoor Attack\n","Label-Consistent Attack Test Accuracy: 0.8040\n","Accuracy Drop: 0.0030\n","\n","Attack 7: Clean-Label Backdoor Attack\n","Clean-Label Attack Test Accuracy: 0.8040\n","Accuracy Drop: 0.0030\n","\n","Attack 9: Topological Backdoor Attack\n","Topological Attack Test Accuracy: 0.7830\n","Accuracy Drop: 0.0240\n","\n","Attack 10: Structural Backdoor Attack\n","Structural Attack Test Accuracy: 0.7810\n","Accuracy Drop: 0.0260\n","\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","import copy\n","import numpy as np\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define the GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, input_features, hidden_dim, num_classes):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(input_features, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","# Function to train the model\n","def train(model, data, optimizer):\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test(model, data):\n","    model.eval()\n","    logits = model(data)\n","    pred = logits.argmax(dim=1)\n","    correct = pred[data.test_mask] == data.y[data.test_mask]\n","    acc = correct.sum().item() / data.test_mask.sum().item()\n","    return acc\n","\n","# Prepare data\n","data = dataset[0]\n","input_features = dataset.num_node_features\n","hidden_dim = 16\n","num_classes = dataset.num_classes\n","\n","# Train on clean data\n","clean_model = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(clean_model.parameters(), lr=0.01, weight_decay=5e-4)\n","\n","for epoch in range(200):\n","    train(clean_model, data, optimizer)\n","\n","clean_test_acc = test(clean_model, data)\n","print(f'Clean Test Accuracy: {clean_test_acc:.4f}')\n","\n","# Helper functions to inject backdoor attacks\n","\n","# Attack 1: Subgraph-Based Backdoor Attack\n","def subgraph_backdoor_attack(data, trigger_nodes, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Add edges to form a triangle (subgraph trigger)\n","    new_edges = torch.tensor([\n","        [trigger_nodes[0], trigger_nodes[1]],\n","        [trigger_nodes[1], trigger_nodes[2]],\n","        [trigger_nodes[2], trigger_nodes[0]]\n","    ], dtype=torch.long).t()\n","    poisoned_data.edge_index = torch.cat([poisoned_data.edge_index, new_edges], dim=1)\n","    # Assign target class to trigger nodes\n","    poisoned_data.y[trigger_nodes] = target_class\n","    return poisoned_data\n","\n","# Attack 2: Feature-Based Backdoor Attack\n","def feature_backdoor_attack(data, trigger_nodes, feature_dim, trigger_value, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Modify features to include trigger\n","    poisoned_data.x[trigger_nodes, feature_dim] = trigger_value\n","    # Assign target class to trigger nodes\n","    poisoned_data.y[trigger_nodes] = target_class\n","    return poisoned_data\n","\n","# Attack 3: Edge Manipulation Backdoor Attack\n","def edge_manipulation_backdoor_attack(data, trigger_node, connect_nodes, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Connect trigger_node to a set of nodes to form a pattern\n","    new_edges = torch.tensor([[trigger_node]*len(connect_nodes), connect_nodes], dtype=torch.long)\n","    poisoned_data.edge_index = torch.cat([poisoned_data.edge_index, new_edges], dim=1)\n","    # Assign target class to trigger node\n","    poisoned_data.y[trigger_node] = target_class\n","    return poisoned_data\n","\n","# Attack 4: Global Trigger Backdoor Attack\n","def global_trigger_backdoor_attack(data, scaling_factor, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Scale all node features by scaling_factor\n","    poisoned_data.x = poisoned_data.x * scaling_factor\n","    # Assign target class to all nodes (extreme case)\n","    poisoned_data.y[:] = target_class\n","    return poisoned_data\n","\n","# Attack 5: Local Trigger Backdoor Attack\n","def local_trigger_backdoor_attack(data, trigger_node, neighbor_nodes, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Modify a subgraph around trigger_node\n","    for neighbor in neighbor_nodes:\n","        poisoned_data.x[neighbor] = poisoned_data.x[neighbor] * 1.5\n","    # Assign target class to trigger node\n","    poisoned_data.y[trigger_node] = target_class\n","    return poisoned_data\n","\n","# Function to retrain and test the model after an attack\n","def retrain_and_evaluate(attack_name, poisoned_data):\n","    model = GCN(input_features, hidden_dim, num_classes)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    for epoch in range(200):\n","        train(model, poisoned_data, optimizer)\n","    test_acc = test(model, poisoned_data)\n","    accuracy_drop = clean_test_acc - test_acc\n","    print(f'{attack_name} Test Accuracy: {test_acc:.4f}')\n","    print(f'Accuracy Drop: {accuracy_drop:.4f}\\n')\n","\n","# Apply Attack 1: Subgraph-Based Backdoor Attack\n","trigger_nodes = [0, 1, 2]  # Nodes to modify\n","target_class = data.y.max().item()  # Use the maximum class label as the target\n","poisoned_data = subgraph_backdoor_attack(data, trigger_nodes, target_class)\n","print(\"Attack 1: Subgraph-Based Backdoor Attack\")\n","retrain_and_evaluate(\"Subgraph Attack\", poisoned_data)\n","\n","# Apply Attack 2: Feature-Based Backdoor Attack\n","feature_dim = 0  # Feature dimension to modify\n","trigger_value = data.x[:, feature_dim].max() + 10  # Set a high value as trigger\n","poisoned_data = feature_backdoor_attack(data, trigger_nodes, feature_dim, trigger_value, target_class)\n","print(\"Attack 2: Feature-Based Backdoor Attack\")\n","retrain_and_evaluate(\"Feature Attack\", poisoned_data)\n","\n","# Apply Attack 3: Edge Manipulation Backdoor Attack\n","trigger_node = 0\n","connect_nodes = [10, 20, 30]  # Nodes to connect with trigger_node\n","poisoned_data = edge_manipulation_backdoor_attack(data, trigger_node, connect_nodes, target_class)\n","print(\"Attack 3: Edge Manipulation Backdoor Attack\")\n","retrain_and_evaluate(\"Edge Manipulation Attack\", poisoned_data)\n","\n","# Apply Attack 4: Global Trigger Backdoor Attack\n","scaling_factor = 1.5  # Scaling factor for all node features\n","poisoned_data = global_trigger_backdoor_attack(data, scaling_factor, target_class)\n","print(\"Attack 4: Global Trigger Backdoor Attack\")\n","retrain_and_evaluate(\"Global Trigger Attack\", poisoned_data)\n","\n","# Apply Attack 5: Local Trigger Backdoor Attack\n","trigger_node = 0\n","neighbor_nodes = data.edge_index[1][data.edge_index[0] == trigger_node].tolist()\n","poisoned_data = local_trigger_backdoor_attack(data, trigger_node, neighbor_nodes, target_class)\n","print(\"Attack 5: Local Trigger Backdoor Attack\")\n","retrain_and_evaluate(\"Local Trigger Attack\", poisoned_data)\n","\n","# For Attacks 6 to 10, we will provide code snippets and explanations.\n","\n","# Attack 6: Label-Consistent Backdoor Attack\n","# Description: Poisoned samples retain their original labels.\n","\n","def label_consistent_backdoor_attack(data, trigger_nodes, feature_dim, trigger_value):\n","    poisoned_data = copy.deepcopy(data)\n","    poisoned_data.x[trigger_nodes, feature_dim] = trigger_value\n","    # Labels remain the same\n","    return poisoned_data\n","\n","# Apply Attack 6\n","feature_dim = 0\n","trigger_value = data.x[:, feature_dim].mean()\n","poisoned_data = label_consistent_backdoor_attack(data, trigger_nodes, feature_dim, trigger_value)\n","print(\"Attack 6: Label-Consistent Backdoor Attack\")\n","retrain_and_evaluate(\"Label-Consistent Attack\", poisoned_data)\n","\n","# Attack 7: Clean-Label Backdoor Attack\n","# Similar to Label-Consistent but focuses on making poisoned samples indistinguishable.\n","\n","def clean_label_backdoor_attack(data, trigger_nodes, feature_dim, trigger_value):\n","    poisoned_data = copy.deepcopy(data)\n","    poisoned_data.x[trigger_nodes, feature_dim] = trigger_value\n","    # Labels remain the same\n","    return poisoned_data\n","\n","# Apply Attack 7\n","poisoned_data = clean_label_backdoor_attack(data, trigger_nodes, feature_dim, trigger_value)\n","print(\"Attack 7: Clean-Label Backdoor Attack\")\n","retrain_and_evaluate(\"Clean-Label Attack\", poisoned_data)\n","\n","# Attack 8: Dynamic Graph Backdoor Attack\n","# Not applicable to static datasets like Cora. Skipping implementation.\n","\n","# Attack 9: Topological Backdoor Attack\n","def topological_backdoor_attack(data, trigger_nodes, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Create a unique community structure\n","    for i in range(len(trigger_nodes) - 1):\n","        poisoned_data.edge_index = torch.cat([\n","            poisoned_data.edge_index,\n","            torch.tensor([[trigger_nodes[i], trigger_nodes[i+1]]], dtype=torch.long).t()\n","        ], dim=1)\n","    # Assign target class\n","    poisoned_data.y[trigger_nodes] = target_class\n","    return poisoned_data\n","\n","# Apply Attack 9\n","poisoned_data = topological_backdoor_attack(data, trigger_nodes, target_class)\n","print(\"Attack 9: Topological Backdoor Attack\")\n","retrain_and_evaluate(\"Topological Attack\", poisoned_data)\n","\n","# Attack 10: Structural Backdoor Attack\n","def structural_backdoor_attack(data, trigger_node, target_degree, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    current_degree = (poisoned_data.edge_index[0] == trigger_node).sum().item()\n","    # Adjust degree to target_degree\n","    while current_degree < target_degree:\n","        new_node = np.random.randint(0, data.num_nodes)\n","        poisoned_data.edge_index = torch.cat([\n","            poisoned_data.edge_index,\n","            torch.tensor([[trigger_node, new_node]], dtype=torch.long).t()\n","        ], dim=1)\n","        current_degree += 1\n","    # Assign target class\n","    poisoned_data.y[trigger_node] = target_class\n","    return poisoned_data\n","\n","# Apply Attack 10\n","target_degree = 50  # Increase degree to 50\n","poisoned_data = structural_backdoor_attack(data, trigger_node, target_degree, target_class)\n","print(\"Attack 10: Structural Backdoor Attack\")\n","retrain_and_evaluate(\"Structural Attack\", poisoned_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89430,"status":"ok","timestamp":1730026239501,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-300},"id":"EKtHiOLgjY9O","outputId":"5ea4239d-b2e1-4777-9a0a-cab60719f5bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Clean Test Accuracy: 0.7970\n","\n","Attack 1: Subgraph-Based Backdoor Attack\n","Test Accuracy without Defense: 0.7930\n","Accuracy Drop without Defense: 0.0040\n","Applying Defense: Anomaly Detection by Degree\n","Subgraph Attack Test Accuracy after Defense: 0.7759\n","Accuracy Drop after Defense: 0.0211\n","\n","Attack 2: Feature-Based Backdoor Attack\n","Test Accuracy without Defense: 0.7950\n","Accuracy Drop without Defense: 0.0020\n","Applying Defense: Anomaly Detection by PCA\n","Feature Attack Test Accuracy after Defense: 0.7794\n","Accuracy Drop after Defense: 0.0176\n","\n","Attack 3: Edge Manipulation Backdoor Attack\n","Test Accuracy without Defense: 0.7830\n","Accuracy Drop without Defense: 0.0140\n","Applying Defense: Edge Filtering by Betweenness Centrality\n","Edge Manipulation Attack Test Accuracy after Defense: 0.7860\n","Accuracy Drop after Defense: 0.0110\n","\n","Attack 4: Global Trigger Backdoor Attack\n","Test Accuracy without Defense: 1.0000\n","Accuracy Drop without Defense: -0.2030\n","Applying Defense: Feature Normalization\n","Global Trigger Attack Test Accuracy after Defense: 1.0000\n","Accuracy Drop after Defense: -0.2030\n","\n","Attack 5: Local Trigger Backdoor Attack\n","Test Accuracy without Defense: 0.7860\n","Accuracy Drop without Defense: 0.0110\n","Applying Defense: Graph Purification by Smoothing\n","Local Trigger Attack Test Accuracy after Defense: 0.8010\n","Accuracy Drop after Defense: -0.0040\n","\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.utils import to_networkx, from_networkx\n","import copy\n","import numpy as np\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from scipy.stats import zscore\n","\n","# Load the Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora')\n","\n","# Define the GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, input_features, hidden_dim, num_classes):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(input_features, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","# Function to train the model\n","def train(model, data, optimizer):\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test(model, data):\n","    model.eval()\n","    logits = model(data)\n","    pred = logits.argmax(dim=1)\n","    correct = pred[data.test_mask] == data.y[data.test_mask]\n","    acc = correct.sum().item() / data.test_mask.sum().item()\n","    return acc\n","\n","# Prepare data\n","data = dataset[0]\n","input_features = dataset.num_node_features\n","hidden_dim = 16\n","num_classes = dataset.num_classes\n","\n","# Train on clean data\n","clean_model = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(clean_model.parameters(), lr=0.01, weight_decay=5e-4)\n","\n","for epoch in range(200):\n","    train(clean_model, data, optimizer)\n","\n","clean_test_acc = test(clean_model, data)\n","print(f'Clean Test Accuracy: {clean_test_acc:.4f}\\n')\n","\n","# Helper functions to inject backdoor attacks\n","\n","# Attack 1: Subgraph-Based Backdoor Attack\n","def subgraph_backdoor_attack(data, trigger_nodes, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Add edges to form a triangle (subgraph trigger)\n","    new_edges = torch.tensor([\n","        [trigger_nodes[0], trigger_nodes[1]],\n","        [trigger_nodes[1], trigger_nodes[2]],\n","        [trigger_nodes[2], trigger_nodes[0]]\n","    ], dtype=torch.long).t()\n","    poisoned_data.edge_index = torch.cat([poisoned_data.edge_index, new_edges], dim=1)\n","    # Assign target class to trigger nodes\n","    poisoned_data.y[trigger_nodes] = target_class\n","    return poisoned_data\n","\n","# Defense Method: Anomaly Detection using Z-Score on Degrees\n","def filter_anomalies_by_degree(data):\n","    # Convert edge_index to adjacency matrix\n","    adj = torch.zeros((data.num_nodes, data.num_nodes))\n","    adj[data.edge_index[0], data.edge_index[1]] = 1\n","    degrees = adj.sum(dim=1).numpy()\n","    # Compute Z-scores\n","    z_scores = zscore(degrees)\n","    # Nodes with absolute Z-score > threshold are considered anomalies\n","    threshold = 3  # Adjust as needed\n","    normal_nodes = np.where(np.abs(z_scores) <= threshold)[0]\n","    # Filter nodes and edges\n","    filtered_data = copy.deepcopy(data)\n","    mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","    mask[normal_nodes] = True\n","    filtered_data.x = data.x[mask]\n","    filtered_data.y = data.y[mask]\n","    node_idx = torch.arange(data.num_nodes)[mask]\n","    node_mapping = {old_idx.item(): new_idx for new_idx, old_idx in enumerate(node_idx)}\n","    edge_mask = mask[data.edge_index[0]] & mask[data.edge_index[1]]\n","    filtered_data.edge_index = data.edge_index[:, edge_mask]\n","    # Re-map node indices\n","    filtered_data.edge_index = torch.tensor([\n","        [node_mapping[idx.item()] for idx in filtered_data.edge_index[0]],\n","        [node_mapping[idx.item()] for idx in filtered_data.edge_index[1]]\n","    ], dtype=torch.long)\n","    filtered_data.train_mask = data.train_mask[mask]\n","    filtered_data.val_mask = data.val_mask[mask]\n","    filtered_data.test_mask = data.test_mask[mask]\n","    return filtered_data\n","\n","# Function to retrain and evaluate the model after applying defense\n","def retrain_and_evaluate_defense(attack_name, poisoned_data, defense_method=None):\n","    if defense_method:\n","        defended_data = defense_method(poisoned_data)\n","    else:\n","        defended_data = poisoned_data\n","    model = GCN(input_features, hidden_dim, num_classes)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    for epoch in range(200):\n","        train(model, defended_data, optimizer)\n","    test_acc = test(model, defended_data)\n","    accuracy_drop = clean_test_acc - test_acc\n","    print(f'{attack_name} Test Accuracy after Defense: {test_acc:.4f}')\n","    print(f'Accuracy Drop after Defense: {accuracy_drop:.4f}\\n')\n","    return test_acc\n","\n","# Apply Attack 1: Subgraph-Based Backdoor Attack\n","trigger_nodes = [0, 1, 2]  # Nodes to modify\n","target_class = data.y.max().item()  # Use the maximum class label as the target\n","poisoned_data = subgraph_backdoor_attack(data, trigger_nodes, target_class)\n","print(\"Attack 1: Subgraph-Based Backdoor Attack\")\n","# Retrain without defense\n","model = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","for epoch in range(200):\n","    train(model, poisoned_data, optimizer)\n","test_acc = test(model, poisoned_data)\n","accuracy_drop = clean_test_acc - test_acc\n","print(f'Test Accuracy without Defense: {test_acc:.4f}')\n","print(f'Accuracy Drop without Defense: {accuracy_drop:.4f}')\n","\n","# Apply Defense\n","print(\"Applying Defense: Anomaly Detection by Degree\")\n","defended_test_acc = retrain_and_evaluate_defense(\"Subgraph Attack\", poisoned_data, filter_anomalies_by_degree)\n","\n","# Attack 2: Feature-Based Backdoor Attack\n","def feature_backdoor_attack(data, trigger_nodes, feature_dim, trigger_value, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Modify features to include trigger\n","    poisoned_data.x[trigger_nodes, feature_dim] = trigger_value\n","    # Assign target class to trigger nodes\n","    poisoned_data.y[trigger_nodes] = target_class\n","    return poisoned_data\n","\n","# Defense Method: Anomaly Detection on Features using PCA\n","def filter_anomalies_by_pca(data):\n","    x_numpy = data.x.numpy()\n","    pca = PCA(n_components=2)\n","    x_pca = pca.fit_transform(x_numpy)\n","    # Perform clustering\n","    kmeans = KMeans(n_clusters=num_classes, random_state=0).fit(x_pca)\n","    distances = kmeans.transform(x_pca).min(axis=1)\n","    threshold = np.percentile(distances, 95)  # Adjust as needed\n","    normal_nodes = np.where(distances <= threshold)[0]\n","    # Filter nodes and edges\n","    filtered_data = copy.deepcopy(data)\n","    mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","    mask[normal_nodes] = True\n","    filtered_data.x = data.x[mask]\n","    filtered_data.y = data.y[mask]\n","    node_idx = torch.arange(data.num_nodes)[mask]\n","    node_mapping = {old_idx.item(): new_idx for new_idx, old_idx in enumerate(node_idx)}\n","    edge_mask = mask[data.edge_index[0]] & mask[data.edge_index[1]]\n","    filtered_data.edge_index = data.edge_index[:, edge_mask]\n","    # Re-map node indices\n","    filtered_data.edge_index = torch.tensor([\n","        [node_mapping[idx.item()] for idx in filtered_data.edge_index[0]],\n","        [node_mapping[idx.item()] for idx in filtered_data.edge_index[1]]\n","    ], dtype=torch.long)\n","    filtered_data.train_mask = data.train_mask[mask]\n","    filtered_data.val_mask = data.val_mask[mask]\n","    filtered_data.test_mask = data.test_mask[mask]\n","    return filtered_data\n","\n","# Apply Attack 2\n","feature_dim = 0  # Feature dimension to modify\n","trigger_value = data.x[:, feature_dim].max() + 10  # Set a high value as trigger\n","poisoned_data = feature_backdoor_attack(data, trigger_nodes, feature_dim, trigger_value, target_class)\n","print(\"Attack 2: Feature-Based Backdoor Attack\")\n","# Retrain without defense\n","model = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","for epoch in range(200):\n","    train(model, poisoned_data, optimizer)\n","test_acc = test(model, poisoned_data)\n","accuracy_drop = clean_test_acc - test_acc\n","print(f'Test Accuracy without Defense: {test_acc:.4f}')\n","print(f'Accuracy Drop without Defense: {accuracy_drop:.4f}')\n","\n","# Apply Defense\n","print(\"Applying Defense: Anomaly Detection by PCA\")\n","defended_test_acc = retrain_and_evaluate_defense(\"Feature Attack\", poisoned_data, filter_anomalies_by_pca)\n","\n","# Attack 3: Edge Manipulation Backdoor Attack\n","def edge_manipulation_backdoor_attack(data, trigger_node, connect_nodes, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Connect trigger_node to a set of nodes to form a pattern\n","    new_edges = torch.tensor([[trigger_node]*len(connect_nodes), connect_nodes], dtype=torch.long)\n","    poisoned_data.edge_index = torch.cat([poisoned_data.edge_index, new_edges], dim=1)\n","    # Assign target class to trigger node\n","    poisoned_data.y[trigger_node] = target_class\n","    return poisoned_data\n","\n","# Defense Method: Edge Removal based on Betweenness Centrality\n","def filter_edges_by_betweenness(data):\n","    G = to_networkx(data, to_undirected=True)\n","    edge_betweenness = nx.edge_betweenness_centrality(G)\n","    # Remove edges with high betweenness centrality\n","    threshold = np.percentile(list(edge_betweenness.values()), 95)  # Adjust as needed\n","    edges_to_remove = [edge for edge, centrality in edge_betweenness.items() if centrality > threshold]\n","    G.remove_edges_from(edges_to_remove)\n","    # Convert back to PyTorch Geometric data\n","    filtered_data = copy.deepcopy(data)\n","    filtered_data.edge_index = from_networkx(G).edge_index\n","    return filtered_data\n","\n","import networkx as nx  # Import networkx for graph analysis\n","\n","# Apply Attack 3\n","trigger_node = 0\n","connect_nodes = [10, 20, 30]  # Nodes to connect with trigger_node\n","poisoned_data = edge_manipulation_backdoor_attack(data, trigger_node, connect_nodes, target_class)\n","print(\"Attack 3: Edge Manipulation Backdoor Attack\")\n","# Retrain without defense\n","model = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","for epoch in range(200):\n","    train(model, poisoned_data, optimizer)\n","test_acc = test(model, poisoned_data)\n","accuracy_drop = clean_test_acc - test_acc\n","print(f'Test Accuracy without Defense: {test_acc:.4f}')\n","print(f'Accuracy Drop without Defense: {accuracy_drop:.4f}')\n","\n","# Apply Defense\n","print(\"Applying Defense: Edge Filtering by Betweenness Centrality\")\n","defended_test_acc = retrain_and_evaluate_defense(\"Edge Manipulation Attack\", poisoned_data, filter_edges_by_betweenness)\n","\n","# Attack 4: Global Trigger Backdoor Attack\n","def global_trigger_backdoor_attack(data, scaling_factor, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Scale all node features by scaling_factor\n","    poisoned_data.x = poisoned_data.x * scaling_factor\n","    # Assign target class to all nodes (extreme case)\n","    poisoned_data.y[:] = target_class\n","    return poisoned_data\n","\n","# Defense Method: Feature Normalization\n","def normalize_features(data):\n","    normalized_data = copy.deepcopy(data)\n","    normalized_data.x = F.normalize(data.x, p=2, dim=1)\n","    return normalized_data\n","\n","# Apply Attack 4\n","scaling_factor = 1.5  # Scaling factor for all node features\n","poisoned_data = global_trigger_backdoor_attack(data, scaling_factor, target_class)\n","print(\"Attack 4: Global Trigger Backdoor Attack\")\n","# Retrain without defense\n","model = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","for epoch in range(200):\n","    train(model, poisoned_data, optimizer)\n","test_acc = test(model, poisoned_data)\n","accuracy_drop = clean_test_acc - test_acc\n","print(f'Test Accuracy without Defense: {test_acc:.4f}')\n","print(f'Accuracy Drop without Defense: {accuracy_drop:.4f}')\n","\n","# Apply Defense\n","print(\"Applying Defense: Feature Normalization\")\n","defended_data = normalize_features(poisoned_data)\n","defended_test_acc = retrain_and_evaluate_defense(\"Global Trigger Attack\", defended_data)\n","\n","# Attack 5: Local Trigger Backdoor Attack\n","def local_trigger_backdoor_attack(data, trigger_node, neighbor_nodes, target_class):\n","    poisoned_data = copy.deepcopy(data)\n","    # Modify features of neighbor nodes\n","    for neighbor in neighbor_nodes:\n","        poisoned_data.x[neighbor] = poisoned_data.x[neighbor] * 1.5\n","    # Assign target class to trigger node\n","    poisoned_data.y[trigger_node] = target_class\n","    return poisoned_data\n","\n","# Defense Method: Graph Purification by Smoothing\n","def graph_purification_smoothing(data):\n","    purified_data = copy.deepcopy(data)\n","    edge_index = data.edge_index\n","    x = data.x\n","    # Simple smoothing: each node feature is averaged with its neighbors\n","    for node in range(data.num_nodes):\n","        neighbors = edge_index[1][edge_index[0] == node]\n","        if len(neighbors) > 0:\n","            neighbor_features = x[neighbors]\n","            purified_data.x[node] = (x[node] + neighbor_features.mean(dim=0)) / 2\n","    return purified_data\n","\n","# Apply Attack 5\n","trigger_node = 0\n","neighbor_nodes = data.edge_index[1][data.edge_index[0] == trigger_node].tolist()\n","poisoned_data = local_trigger_backdoor_attack(data, trigger_node, neighbor_nodes, target_class)\n","print(\"Attack 5: Local Trigger Backdoor Attack\")\n","# Retrain without defense\n","model = GCN(input_features, hidden_dim, num_classes)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","for epoch in range(200):\n","    train(model, poisoned_data, optimizer)\n","test_acc = test(model, poisoned_data)\n","accuracy_drop = clean_test_acc - test_acc\n","print(f'Test Accuracy without Defense: {test_acc:.4f}')\n","print(f'Accuracy Drop without Defense: {accuracy_drop:.4f}')\n","\n","# Apply Defense\n","print(\"Applying Defense: Graph Purification by Smoothing\")\n","defended_data = graph_purification_smoothing(poisoned_data)\n","defended_test_acc = retrain_and_evaluate_defense(\"Local Trigger Attack\", defended_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZTZXWpvmBLZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KC5lFge28DRO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43382,"status":"ok","timestamp":1730753632903,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-60},"id":"etZluiN18DLa","outputId":"5a71759f-242d-4d93-b5d0-24b5ff656e54"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on clean data: 0.82\n","Accuracy after node_level_attack: 0.813\n","Accuracy after edge_level_attack: 0.809\n","Accuracy after subgraph_attack: 0.813\n","Accuracy after augmentation of node_level_attack: 0.815\n","Accuracy after augmentation of edge_level_attack: 0.818\n","Accuracy after augmentation of subgraph_attack: 0.801\n","Accuracy on clean data: 0.82\n","Accuracy drop after node_level_attack: 0.007000000000000006\n","Recovered accuracy after augmentation: 0.815\n","Accuracy drop after edge_level_attack: 0.010999999999999899\n","Recovered accuracy after augmentation: 0.818\n","Accuracy drop after subgraph_attack: 0.007000000000000006\n","Recovered accuracy after augmentation: 0.801\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.transforms import NormalizeFeatures\n","from sklearn.metrics import accuracy_score\n","\n","# Load and preprocess Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora', transform=NormalizeFeatures())\n","data = dataset[0]\n","\n","# Define GNN model\n","class GCN(torch.nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_features, 16)\n","        self.conv2 = GCNConv(16, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize model, optimizer, and data\n","model = GCN()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","data = data.to(device)\n","model = model.to(device)\n","\n","# Function to train the model\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test():\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n","    return acc\n","\n","# Train and evaluate on clean data\n","clean_accuracies = []\n","for epoch in range(200):\n","    train()\n","    acc = test()\n","    clean_accuracies.append(acc)\n","print(\"Accuracy on clean data:\", clean_accuracies[-1])\n","\n","# Implement Poisoning Attacks\n","# Here, create different poisoned versions of the dataset:\n","# Node-Level Attack: Modify node features.\n","# Edge-Level Attack: Add or remove edges.\n","# Subgraph Attack: Inject an adversarial subgraph.\n","\n","def node_level_attack(data, poison_rate=0.5):\n","    num_poison = int(poison_rate * data.num_nodes)\n","    for _ in range(num_poison):\n","        node = torch.randint(0, data.num_nodes, (1,))\n","        data.x[node] = torch.rand(data.x[node].shape)\n","    return data\n","\n","def edge_level_attack(data, poison_rate=0.5):\n","    num_poison = int(poison_rate * data.num_edges)\n","    edge_index = data.edge_index.clone()\n","\n","    for _ in range(num_poison):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]])\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","def subgraph_attack(data, poison_rate=0.5):\n","    edge_index = data.edge_index.clone()\n","    subgraph_size = int(poison_rate * data.num_nodes)\n","\n","    for _ in range(subgraph_size):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]])\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","\n","# Apply poisoning and test\n","poisoned_accuracies = {}\n","for attack_fn in [node_level_attack, edge_level_attack, subgraph_attack]:\n","    poisoned_data = attack_fn(data.clone())\n","    poisoned_acc = []\n","    for epoch in range(200):\n","        train()\n","        poisoned_acc.append(test())\n","    poisoned_accuracies[attack_fn.__name__] = poisoned_acc\n","    print(f\"Accuracy after {attack_fn.__name__}:\", poisoned_acc[-1])\n","\n","# Applying Augmentation (e.g., dropout, feature smoothing, etc.) to improve poisoned accuracy\n","def augment(data):\n","    data.x = F.dropout(data.x, p=0.5, training=True)  # Example of feature dropout\n","    # Additional augmentations can be added here.\n","    return data\n","\n","# Retrain with augmented poisoned data\n","augmented_accuracies = {}\n","for attack_fn in [node_level_attack, edge_level_attack, subgraph_attack]:\n","    poisoned_data = augment(attack_fn(data.clone()))\n","    augmented_acc = []\n","    for epoch in range(200):\n","        train()\n","        augmented_acc.append(test())\n","    augmented_accuracies[attack_fn.__name__] = augmented_acc\n","    print(f\"Accuracy after augmentation of {attack_fn.__name__}:\", augmented_acc[-1])\n","\n","# Display accuracy drops and improvements\n","print(\"Accuracy on clean data:\", clean_accuracies[-1])\n","for attack, acc in poisoned_accuracies.items():\n","    print(f\"Accuracy drop after {attack}: {clean_accuracies[-1] - acc[-1]}\")\n","    print(f\"Recovered accuracy after augmentation: {augmented_accuracies[attack][-1]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"byfrYZjD8DHX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58658,"status":"ok","timestamp":1730754373619,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-60},"id":"FY28OG7Q5Hdi","outputId":"f140023a-b445-449b-ed28-bea9f961f9c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on clean data: 0.8\n","Accuracy after node_level_attack: 0.81\n","Accuracy after Node-Level Augmentation: 0.812\n","Accuracy after edge_level_attack: 0.8\n","Accuracy after Edge-Level Augmentation: 0.807\n","Accuracy after subgraph_attack: 0.812\n","Accuracy after Subgraph Augmentation: 0.813\n","Accuracy after subgraph_attack: 0.813\n","Accuracy after Graph-Level Augmentation: 0.807\n","\n","Final Results:\n","node_level_attack:\n","  Accuracy after attack: 0.81\n","  Accuracy after augmentation: 0.812\n","edge_level_attack:\n","  Accuracy after attack: 0.8\n","  Accuracy after augmentation: 0.807\n","subgraph_attack:\n","  Accuracy after attack: 0.813\n","  Accuracy after augmentation: 0.807\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.transforms import NormalizeFeatures\n","from sklearn.metrics import accuracy_score\n","\n","# Load and preprocess Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora', transform=NormalizeFeatures())\n","data = dataset[0]\n","\n","# Define GNN model\n","class GCN(torch.nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_features, 16)\n","        self.conv2 = GCNConv(16, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize model, optimizer, and data\n","model = GCN()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","data = data.to(device)\n","model = model.to(device)\n","\n","# Function to train the model\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test():\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n","    return acc\n","\n","# Train and evaluate on clean data\n","clean_accuracies = []\n","for epoch in range(200):\n","    train()\n","    acc = test()\n","    clean_accuracies.append(acc)\n","print(\"Accuracy on clean data:\", clean_accuracies[-1])\n","\n","# Poisoning Attack Functions\n","def node_level_attack(data, poison_rate=0.1):\n","    num_poison = int(poison_rate * data.num_nodes)\n","    for _ in range(num_poison):\n","        node = torch.randint(0, data.num_nodes, (1,))\n","        data.x[node] = torch.rand(data.x[node].shape)\n","    return data\n","\n","def edge_level_attack(data, poison_rate=0.1):\n","    num_poison = int(poison_rate * data.num_edges)\n","    edge_index = data.edge_index.clone()\n","\n","    for _ in range(num_poison):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]])\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","def subgraph_attack(data, poison_rate=0.1):\n","    edge_index = data.edge_index.clone()\n","    subgraph_size = int(poison_rate * data.num_nodes)\n","\n","    for _ in range(subgraph_size):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]])\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","# Augmentation Functions\n","def node_level_augmentation(data):\n","    data.x = F.dropout(data.x, p=0.1, training=True)\n","    return data\n","\n","def edge_level_augmentation(data):\n","    edge_index = data.edge_index\n","    mask = torch.rand(edge_index.size(1)) > 0.1\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def subgraph_augmentation(data, subgraph_nodes):\n","    edge_index = data.edge_index\n","    for node in subgraph_nodes:\n","        target = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node], [target]])\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","    data.edge_index = edge_index\n","    return data\n","\n","def graph_level_augmentation(data):\n","    noise = torch.randn_like(data.x) * 0.1\n","    data.x = data.x + noise\n","    return data\n","\n","# Apply Poisoning Attacks and test accuracy, then apply augmentations and re-test accuracy\n","results = {}\n","\n","# Define subgraph nodes for subgraph augmentation\n","subgraph_nodes = torch.randperm(data.num_nodes)[:int(0.1 * data.num_nodes)]\n","\n","# Run each attack, measure accuracy, then apply corresponding augmentation\n","for attack_fn, augment_fn, augment_name in [\n","    (node_level_attack, node_level_augmentation, \"Node-Level Augmentation\"),\n","    (edge_level_attack, edge_level_augmentation, \"Edge-Level Augmentation\"),\n","    (subgraph_attack, lambda d: subgraph_augmentation(d, subgraph_nodes), \"Subgraph Augmentation\"),\n","    (subgraph_attack, graph_level_augmentation, \"Graph-Level Augmentation\")  # Using subgraph attack for graph-level test\n","]:\n","    # Reset model to baseline and apply attack\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    poisoned_data = attack_fn(data.clone())\n","\n","    # Train on attacked data\n","    attack_acc = []\n","    for epoch in range(200):\n","        train()\n","        attack_acc.append(test())\n","\n","    print(f\"Accuracy after {attack_fn.__name__}:\", attack_acc[-1])\n","\n","    # Apply augmentation to the attacked data\n","    augmented_data = augment_fn(poisoned_data.clone())\n","\n","    # Reset model and retrain on augmented data\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    augmented_acc = []\n","    for epoch in range(200):\n","        train()\n","        augmented_acc.append(test())\n","\n","    print(f\"Accuracy after {augment_name}:\", augmented_acc[-1])\n","\n","    # Store results\n","    results[attack_fn.__name__] = {\n","        \"poisoned_accuracy\": attack_acc[-1],\n","        \"augmented_accuracy\": augmented_acc[-1]\n","    }\n","\n","# Display results\n","print(\"\\nFinal Results:\")\n","for attack, result in results.items():\n","    print(f\"{attack}:\")\n","    print(f\"  Accuracy after attack: {result['poisoned_accuracy']}\")\n","    print(f\"  Accuracy after augmentation: {result['augmented_accuracy']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82950,"status":"ok","timestamp":1730756810872,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-60},"id":"cnK9LiT45HiJ","outputId":"2495a6b9-440e-4e4d-a6a0-1f7c857bd59f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on clean data: 0.806\n","Accuracy after node_level_attack: 0.819\n","Accuracy after augmentation (node_level_augmentation): 0.803\n","Accuracy after filtration (Structural Relationship Analysis): 0.812\n","Accuracy after edge_level_attack: 0.811\n","Accuracy after augmentation (edge_level_augmentation): 0.813\n","Accuracy after filtration (Feature Manipulation Detection): 0.814\n","Accuracy after subgraph_attack: 0.811\n","Accuracy after augmentation (<lambda>): 0.806\n","Accuracy after filtration (Edge Alteration Detection): 0.782\n","Accuracy after subgraph_attack: 0.804\n","Accuracy after augmentation (graph_level_augmentation): 0.81\n","Accuracy after filtration (Pattern-Based Anomaly Detection): 0.808\n","\n","Final Results:\n","Structural Relationship Analysis:\n","  Accuracy after attack: 0.819\n","  Accuracy after augmentation: 0.803\n","  Accuracy after filtration: 0.812\n","Feature Manipulation Detection:\n","  Accuracy after attack: 0.811\n","  Accuracy after augmentation: 0.813\n","  Accuracy after filtration: 0.814\n","Edge Alteration Detection:\n","  Accuracy after attack: 0.811\n","  Accuracy after augmentation: 0.806\n","  Accuracy after filtration: 0.782\n","Pattern-Based Anomaly Detection:\n","  Accuracy after attack: 0.804\n","  Accuracy after augmentation: 0.81\n","  Accuracy after filtration: 0.808\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.transforms import NormalizeFeatures\n","from sklearn.metrics import accuracy_score\n","\n","# Load and preprocess Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora', transform=NormalizeFeatures())\n","data = dataset[0]\n","\n","# Define GNN model\n","class GCN(torch.nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_features, 16)\n","        self.conv2 = GCNConv(16, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize model, optimizer, and data\n","model = GCN()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","data = data.to(device)\n","model = model.to(device)\n","\n","# Function to train the model\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test():\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n","    return acc\n","\n","# Train and evaluate on clean data\n","clean_accuracies = []\n","for epoch in range(200):\n","    train()\n","    acc = test()\n","    clean_accuracies.append(acc)\n","print(\"Accuracy on clean data:\", clean_accuracies[-1])\n","\n","# Poisoning Attack Functions\n","def node_level_attack(data, poison_rate=0.20):\n","    num_poison = int(poison_rate * data.num_nodes)\n","    for _ in range(num_poison):\n","        node = torch.randint(0, data.num_nodes, (1,))\n","        data.x[node] = torch.rand(data.x[node].shape)\n","    return data\n","\n","def edge_level_attack(data, poison_rate=0.20):\n","    num_poison = int(poison_rate * data.num_edges)\n","    edge_index = data.edge_index.clone()\n","\n","    for _ in range(num_poison):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","def subgraph_attack(data, poison_rate=0.20):\n","    edge_index = data.edge_index.clone()\n","    subgraph_size = int(poison_rate * data.num_nodes)\n","\n","    for _ in range(subgraph_size):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","# Augmentation Functions\n","def node_level_augmentation(data):\n","    data.x = F.dropout(data.x, p=0.1, training=True)\n","    return data\n","\n","def edge_level_augmentation(data):\n","    edge_index = data.edge_index\n","    mask = torch.rand(edge_index.size(1)) > 0.1\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def subgraph_augmentation(data, subgraph_nodes):\n","    edge_index = data.edge_index\n","    for node in subgraph_nodes:\n","        target = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node], [target]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","    data.edge_index = edge_index\n","    return data\n","\n","def graph_level_augmentation(data):\n","    noise = torch.randn_like(data.x) * 0.1\n","    data.x = data.x + noise\n","    return data\n","\n","# Filtration Methods\n","def structural_relationship_analysis(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if (data.x[node1] - data.x[node2]).norm() > 1.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def feature_manipulation_detection(data):\n","    for node in range(data.num_nodes):\n","        neighbors = data.edge_index[1][data.edge_index[0] == node]\n","        if neighbors.size(0) > 0:\n","            avg_feature = data.x[neighbors].mean(dim=0)\n","            if (data.x[node] - avg_feature).norm() > 0.5:\n","                data.x[node] = avg_feature\n","    return data\n","\n","def edge_alteration_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(node1 - node2) > 10:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def pattern_based_anomaly_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(data.x[node1].sum() - data.x[node2].sum()) > 5.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","# Testing each filtration method's effectiveness after poisoning and augmentations\n","results = {}\n","\n","# Define subgraph nodes for subgraph augmentation\n","subgraph_nodes = torch.randperm(data.num_nodes)[:int(0.1 * data.num_nodes)]\n","\n","# Run each attack, measure accuracy, then apply augmentation and filtration\n","attack_augment_filter_combinations = [\n","    (\"node_level_attack\", node_level_augmentation, structural_relationship_analysis, \"Structural Relationship Analysis\"),\n","    (\"edge_level_attack\", edge_level_augmentation, feature_manipulation_detection, \"Feature Manipulation Detection\"),\n","    (\"subgraph_attack\", lambda d: subgraph_augmentation(d, subgraph_nodes), edge_alteration_detection, \"Edge Alteration Detection\"),\n","    (\"subgraph_attack\", graph_level_augmentation, pattern_based_anomaly_detection, \"Pattern-Based Anomaly Detection\"),\n","]\n","\n","for attack_fn_name, augment_fn, filter_fn, filter_name in attack_augment_filter_combinations:\n","    # Apply attack\n","    attack_fn = globals()[attack_fn_name]\n","    poisoned_data = attack_fn(data.clone())\n","\n","    # Measure accuracy after attack\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    attack_acc = []\n","    for epoch in range(200):\n","        train()\n","        attack_acc.append(test())\n","    print(f\"Accuracy after {attack_fn_name}:\", attack_acc[-1])\n","\n","    # Apply augmentation and measure accuracy\n","    augmented_data = augment_fn(poisoned_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    augmented_acc = []\n","    for epoch in range(200):\n","        train()\n","        augmented_acc.append(test())\n","    print(f\"Accuracy after augmentation ({augment_fn.__name__}):\", augmented_acc[-1])\n","\n","    # Apply filtration method and measure final accuracy\n","    filtered_data = filter_fn(augmented_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    filtered_acc = []\n","    for epoch in range(200):\n","        train()\n","        filtered_acc.append(test())\n","    print(f\"Accuracy after filtration ({filter_name}):\", filtered_acc[-1])\n","\n","    # Store results\n","    results[filter_name] = {\n","        \"poisoned_accuracy\": attack_acc[-1],\n","        \"augmented_accuracy\": augmented_acc[-1],\n","        \"filtered_accuracy\": filtered_acc[-1]\n","    }\n","\n","# Display results\n","print(\"\\nFinal Results:\")\n","for filter_name, result in results.items():\n","    print(f\"{filter_name}:\")\n","    print(f\"  Accuracy after attack: {result['poisoned_accuracy']}\")\n","    print(f\"  Accuracy after augmentation: {result['augmented_accuracy']}\")\n","    print(f\"  Accuracy after filtration: {result['filtered_accuracy']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83217,"status":"ok","timestamp":1730757466642,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-60},"id":"8Phx2ZT8B6us","outputId":"b795bd15-6e16-4383-fd19-23074c1b684d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on clean data: 0.823\n","Accuracy after node_level_attack: 0.808\n","Accuracy after augmentation (node_level_augmentation): 0.809\n","Accuracy after filtration (Structural Relationship Analysis): 0.811\n","Accuracy after edge_level_attack: 0.801\n","Accuracy after augmentation (edge_level_augmentation): 0.801\n","Accuracy after filtration (Feature Manipulation Detection): 0.81\n","Accuracy after subgraph_attack: 0.806\n","Accuracy after augmentation (<lambda>): 0.816\n","Accuracy after filtration (Edge Alteration Detection): 0.815\n","Accuracy after subgraph_attack: 0.816\n","Accuracy after augmentation (graph_level_augmentation): 0.825\n","Accuracy after filtration (Pattern-Based Anomaly Detection): 0.813\n","\n","Final Results:\n","Structural Relationship Analysis:\n","  Accuracy after attack: 0.808\n","  Accuracy after augmentation: 0.809\n","  Accuracy after filtration: 0.811\n","Feature Manipulation Detection:\n","  Accuracy after attack: 0.801\n","  Accuracy after augmentation: 0.801\n","  Accuracy after filtration: 0.81\n","Edge Alteration Detection:\n","  Accuracy after attack: 0.806\n","  Accuracy after augmentation: 0.816\n","  Accuracy after filtration: 0.815\n","Pattern-Based Anomaly Detection:\n","  Accuracy after attack: 0.816\n","  Accuracy after augmentation: 0.825\n","  Accuracy after filtration: 0.813\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.transforms import NormalizeFeatures\n","from sklearn.metrics import accuracy_score\n","\n","# Load and preprocess Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora', transform=NormalizeFeatures())\n","data = dataset[0]\n","\n","# Define GNN model\n","class GCN(torch.nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_features, 16)\n","        self.conv2 = GCNConv(16, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize model, optimizer, and data\n","model = GCN()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","data = data.to(device)\n","model = model.to(device)\n","\n","# Function to train the model\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test():\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n","    return acc\n","\n","# Train and evaluate on clean data\n","clean_accuracies = []\n","for epoch in range(200):\n","    train()\n","    acc = test()\n","    clean_accuracies.append(acc)\n","print(\"Accuracy on clean data:\", clean_accuracies[-1])\n","\n","# Poisoning Attack Functions\n","def node_level_attack(data, poison_rate=0.5):\n","    num_poison = int(poison_rate * data.num_nodes)\n","    for _ in range(num_poison):\n","        node = torch.randint(0, data.num_nodes, (1,))\n","        data.x[node] = torch.rand(data.x[node].shape)  # Randomly alter features\n","    return data\n","\n","def edge_level_attack(data, poison_rate=0.5):\n","    num_poison = int(poison_rate * data.num_edges)\n","    edge_index = data.edge_index.clone()\n","\n","    for _ in range(num_poison):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","def subgraph_attack(data, poison_rate=0.5):\n","    edge_index = data.edge_index.clone()\n","    subgraph_size = int(poison_rate * data.num_nodes)\n","\n","    for _ in range(subgraph_size):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","# Augmentation Functions\n","def node_level_augmentation(data):\n","    data.x = F.dropout(data.x, p=0.1, training=True)\n","    return data\n","\n","def edge_level_augmentation(data):\n","    edge_index = data.edge_index\n","    mask = torch.rand(edge_index.size(1)) > 0.1\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def subgraph_augmentation(data, subgraph_nodes):\n","    edge_index = data.edge_index\n","    for node in subgraph_nodes:\n","        target = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node], [target]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","    data.edge_index = edge_index\n","    return data\n","\n","def graph_level_augmentation(data):\n","    noise = torch.randn_like(data.x) * 0.1\n","    data.x = data.x + noise\n","    return data\n","\n","# Filtration Methods\n","def structural_relationship_analysis(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if (data.x[node1] - data.x[node2]).norm() > 1.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def feature_manipulation_detection(data):\n","    for node in range(data.num_nodes):\n","        neighbors = data.edge_index[1][data.edge_index[0] == node]\n","        if neighbors.size(0) > 0:\n","            avg_feature = data.x[neighbors].mean(dim=0)\n","            if (data.x[node] - avg_feature).norm() > 0.5:\n","                data.x[node] = avg_feature\n","    return data\n","\n","def edge_alteration_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(node1 - node2) > 10:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def pattern_based_anomaly_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(data.x[node1].sum() - data.x[node2].sum()) > 5.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","# Testing each filtration method's effectiveness after poisoning and augmentations\n","results = {}\n","\n","# Define subgraph nodes for subgraph augmentation\n","subgraph_nodes = torch.randperm(data.num_nodes)[:int(0.1 * data.num_nodes)]\n","\n","# Run each attack, measure accuracy, then apply augmentation and filtration\n","attack_augment_filter_combinations = [\n","    (\"node_level_attack\", node_level_augmentation, structural_relationship_analysis, \"Structural Relationship Analysis\"),\n","    (\"edge_level_attack\", edge_level_augmentation, feature_manipulation_detection, \"Feature Manipulation Detection\"),\n","    (\"subgraph_attack\", lambda d: subgraph_augmentation(d, subgraph_nodes), edge_alteration_detection, \"Edge Alteration Detection\"),\n","    (\"subgraph_attack\", graph_level_augmentation, pattern_based_anomaly_detection, \"Pattern-Based Anomaly Detection\"),\n","]\n","\n","for attack_fn_name, augment_fn, filter_fn, filter_name in attack_augment_filter_combinations:\n","    # Apply attack\n","    attack_fn = globals()[attack_fn_name]\n","    poisoned_data = attack_fn(data.clone())\n","\n","    # Measure accuracy after attack\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    attack_acc = []\n","    for epoch in range(200):\n","        train()\n","        attack_acc.append(test())\n","    print(f\"Accuracy after {attack_fn_name}:\", attack_acc[-1])\n","\n","    # Apply augmentation and measure accuracy\n","    augmented_data = augment_fn(poisoned_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    augmented_acc = []\n","    for epoch in range(200):\n","        train()\n","        augmented_acc.append(test())\n","    print(f\"Accuracy after augmentation ({augment_fn.__name__}):\", augmented_acc[-1])\n","\n","    # Apply filtration method and measure final accuracy\n","    filtered_data = filter_fn(augmented_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    filtered_acc = []\n","    for epoch in range(200):\n","        train()\n","        filtered_acc.append(test())\n","    print(f\"Accuracy after filtration ({filter_name}):\", filtered_acc[-1])\n","\n","    # Store results\n","    results[filter_name] = {\n","        \"poisoned_accuracy\": attack_acc[-1],\n","        \"augmented_accuracy\": augmented_acc[-1],\n","        \"filtered_accuracy\": filtered_acc[-1]\n","    }\n","\n","# Display results\n","print(\"\\nFinal Results:\")\n","for filter_name, result in results.items():\n","    print(f\"{filter_name}:\")\n","    print(f\"  Accuracy after attack: {result['poisoned_accuracy']}\")\n","    print(f\"  Accuracy after augmentation: {result['augmented_accuracy']}\")\n","    print(f\"  Accuracy after filtration: {result['filtered_accuracy']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89010,"status":"ok","timestamp":1730758830327,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"},"user_tz":-60},"id":"i7eesQucKXVa","outputId":"9022f64b-8fc8-4a0d-dccb-91d65fa2284f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on clean data: 0.82\n","Accuracy after node_level_attack: 0.807\n","Accuracy after augmentation (node_level_augmentation): 0.817\n","Accuracy after filtration (Structural Relationship Analysis): 0.802\n","Accuracy after edge_level_attack: 0.803\n","Accuracy after augmentation (edge_level_augmentation): 0.806\n","Accuracy after filtration (Feature Manipulation Detection): 0.805\n","Accuracy after subgraph_attack: 0.809\n","Accuracy after augmentation (<lambda>): 0.803\n","Accuracy after filtration (Edge Alteration Detection): 0.814\n","Accuracy after subgraph_attack: 0.807\n","Accuracy after augmentation (graph_level_augmentation): 0.815\n","Accuracy after filtration (Pattern-Based Anomaly Detection): 0.808\n","\n","Final Results:\n","Structural Relationship Analysis:\n","  Accuracy after attack: 0.807\n","  Accuracy after augmentation: 0.817\n","  Accuracy after filtration: 0.802\n","  Is effective (meets threshold): True\n","Feature Manipulation Detection:\n","  Accuracy after attack: 0.803\n","  Accuracy after augmentation: 0.806\n","  Accuracy after filtration: 0.805\n","  Is effective (meets threshold): True\n","Edge Alteration Detection:\n","  Accuracy after attack: 0.809\n","  Accuracy after augmentation: 0.803\n","  Accuracy after filtration: 0.814\n","  Is effective (meets threshold): True\n","Pattern-Based Anomaly Detection:\n","  Accuracy after attack: 0.807\n","  Accuracy after augmentation: 0.815\n","  Accuracy after filtration: 0.808\n","  Is effective (meets threshold): True\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.transforms import NormalizeFeatures\n","from sklearn.metrics import accuracy_score\n","\n","# Load and preprocess Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora', transform=NormalizeFeatures())\n","data = dataset[0]\n","\n","# Define GNN model\n","class GCN(torch.nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_features, 16)\n","        self.conv2 = GCNConv(16, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize model, optimizer, and data\n","model = GCN()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","data = data.to(device)\n","model = model.to(device)\n","\n","# Function to train the model\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test():\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n","    return acc\n","\n","# Train and evaluate on clean data\n","clean_accuracies = []\n","for epoch in range(200):\n","    train()\n","    acc = test()\n","    clean_accuracies.append(acc)\n","clean_accuracy = clean_accuracies[-1]\n","print(\"Accuracy on clean data:\", clean_accuracy)\n","\n","# Set the accuracy threshold to determine effectiveness\n","threshold = clean_accuracy * 0.9  # 90% of the clean accuracy\n","\n","# Poisoning Attack Functions\n","def node_level_attack(data, poison_rate=0.2):\n","    num_poison = int(poison_rate * data.num_nodes)\n","    for _ in range(num_poison):\n","        node = torch.randint(0, data.num_nodes, (1,))\n","        data.x[node] = torch.rand(data.x[node].shape)  # Randomly alter features\n","    return data\n","\n","def edge_level_attack(data, poison_rate=0.2):\n","    num_poison = int(poison_rate * data.num_edges)\n","    edge_index = data.edge_index.clone()\n","\n","    for _ in range(num_poison):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","def subgraph_attack(data, poison_rate=0.2):\n","    edge_index = data.edge_index.clone()\n","    subgraph_size = int(poison_rate * data.num_nodes)\n","\n","    for _ in range(subgraph_size):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","# Augmentation Functions\n","def node_level_augmentation(data):\n","    data.x = F.dropout(data.x, p=0.1, training=True)\n","    return data\n","\n","def edge_level_augmentation(data):\n","    edge_index = data.edge_index\n","    mask = torch.rand(edge_index.size(1)) > 0.1\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def subgraph_augmentation(data, subgraph_nodes):\n","    edge_index = data.edge_index\n","    for node in subgraph_nodes:\n","        target = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node], [target]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","    data.edge_index = edge_index\n","    return data\n","\n","def graph_level_augmentation(data):\n","    noise = torch.randn_like(data.x) * 0.1\n","    data.x = data.x + noise\n","    return data\n","\n","# Filtration Methods\n","def structural_relationship_analysis(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if (data.x[node1] - data.x[node2]).norm() > 1.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def feature_manipulation_detection(data):\n","    for node in range(data.num_nodes):\n","        neighbors = data.edge_index[1][data.edge_index[0] == node]\n","        if neighbors.size(0) > 0:\n","            avg_feature = data.x[neighbors].mean(dim=0)\n","            if (data.x[node] - avg_feature).norm() > 0.5:\n","                data.x[node] = avg_feature\n","    return data\n","\n","def edge_alteration_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(node1 - node2) > 10:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def pattern_based_anomaly_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(data.x[node1].sum() - data.x[node2].sum()) > 5.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","# Testing each filtration method's effectiveness after poisoning and augmentations\n","results = {}\n","\n","# Define subgraph nodes for subgraph augmentation\n","subgraph_nodes = torch.randperm(data.num_nodes)[:int(0.1 * data.num_nodes)]\n","\n","# Run each attack, measure accuracy, then apply augmentation and filtration\n","attack_augment_filter_combinations = [\n","    (\"node_level_attack\", node_level_augmentation, structural_relationship_analysis, \"Structural Relationship Analysis\"),\n","    (\"edge_level_attack\", edge_level_augmentation, feature_manipulation_detection, \"Feature Manipulation Detection\"),\n","    (\"subgraph_attack\", lambda d: subgraph_augmentation(d, subgraph_nodes), edge_alteration_detection, \"Edge Alteration Detection\"),\n","    (\"subgraph_attack\", graph_level_augmentation, pattern_based_anomaly_detection, \"Pattern-Based Anomaly Detection\"),\n","]\n","\n","for attack_fn_name, augment_fn, filter_fn, filter_name in attack_augment_filter_combinations:\n","    # Apply attack\n","    attack_fn = globals()[attack_fn_name]\n","    poisoned_data = attack_fn(data.clone())\n","\n","    # Measure accuracy after attack\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    attack_acc = []\n","    for epoch in range(200):\n","        train()\n","        attack_acc.append(test())\n","    print(f\"Accuracy after {attack_fn_name}:\", attack_acc[-1])\n","\n","    # Apply augmentation and measure accuracy\n","    augmented_data = augment_fn(poisoned_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    augmented_acc = []\n","    for epoch in range(200):\n","        train()\n","        augmented_acc.append(test())\n","    print(f\"Accuracy after augmentation ({augment_fn.__name__}):\", augmented_acc[-1])\n","\n","    # Apply filtration method and measure final accuracy\n","    filtered_data = filter_fn(augmented_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    filtered_acc = []\n","    for epoch in range(200):\n","        train()\n","        filtered_acc.append(test())\n","    print(f\"Accuracy after filtration ({filter_name}):\", filtered_acc[-1])\n","\n","    # Store results and evaluate against the threshold\n","    final_accuracy = filtered_acc[-1]\n","    results[filter_name] = {\n","        \"poisoned_accuracy\": attack_acc[-1],\n","        \"augmented_accuracy\": augmented_acc[-1],\n","        \"filtered_accuracy\": final_accuracy,\n","        \"is_effective\": final_accuracy >= threshold\n","    }\n","\n","# Display results\n","print(\"\\nFinal Results:\")\n","for filter_name, result in results.items():\n","    print(f\"{filter_name}:\")\n","    print(f\"  Accuracy after attack: {result['poisoned_accuracy']}\")\n","    print(f\"  Accuracy after augmentation: {result['augmented_accuracy']}\")\n","    print(f\"  Accuracy after filtration: {result['filtered_accuracy']}\")\n","    print(f\"  Is effective (meets threshold): {result['is_effective']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"7E9YrE_nQom1","outputId":"8e0f6381-7112-4f23-f25d-2245915e628b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n","Processing...\n","Done!\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy on clean data: 0.808\n","Accuracy after node_level_attack: 0.818\n","Attack Success Rate for node_level_attack: -1.24%\n","Accuracy after augmentation (node_level_augmentation): 0.812\n","Accuracy after filtration (Structural Relationship Analysis): 0.804\n","Accuracy after edge_level_attack: 0.82\n","Attack Success Rate for edge_level_attack: -1.49%\n","Accuracy after augmentation (edge_level_augmentation): 0.802\n","Accuracy after filtration (Feature Manipulation Detection): 0.808\n","Accuracy after subgraph_attack: 0.815\n","Attack Success Rate for subgraph_attack: -0.87%\n","Accuracy after augmentation (<lambda>): 0.818\n","Accuracy after filtration (Edge Alteration Detection): 0.794\n","Accuracy after subgraph_attack: 0.818\n","Attack Success Rate for subgraph_attack: -1.24%\n","Accuracy after augmentation (graph_level_augmentation): 0.817\n","Accuracy after filtration (Pattern-Based Anomaly Detection): 0.806\n","\n","Final Results:\n","Structural Relationship Analysis:\n","  Accuracy after attack: 0.818\n","  Attack Success Rate: -1.24%\n","  Accuracy after augmentation: 0.812\n","  Accuracy after filtration: 0.804\n","  Is effective (meets threshold): True\n","Feature Manipulation Detection:\n","  Accuracy after attack: 0.82\n","  Attack Success Rate: -1.49%\n","  Accuracy after augmentation: 0.802\n","  Accuracy after filtration: 0.808\n","  Is effective (meets threshold): True\n","Edge Alteration Detection:\n","  Accuracy after attack: 0.815\n","  Attack Success Rate: -0.87%\n","  Accuracy after augmentation: 0.818\n","  Accuracy after filtration: 0.794\n","  Is effective (meets threshold): True\n","Pattern-Based Anomaly Detection:\n","  Accuracy after attack: 0.818\n","  Attack Success Rate: -1.24%\n","  Accuracy after augmentation: 0.817\n","  Accuracy after filtration: 0.806\n","  Is effective (meets threshold): True\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.transforms import NormalizeFeatures\n","from sklearn.metrics import accuracy_score\n","\n","# Load and preprocess Cora dataset\n","dataset = Planetoid(root='/tmp/Cora', name='Cora', transform=NormalizeFeatures())\n","data = dataset[0]\n","\n","# Define GNN model\n","class GCN(torch.nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_features, 16)\n","        self.conv2 = GCNConv(16, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize model, optimizer, and data\n","model = GCN()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","data = data.to(device)\n","model = model.to(device)\n","\n","# Function to train the model\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test():\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n","    return acc\n","\n","# Train and evaluate on clean data\n","clean_accuracies = []\n","for epoch in range(200):\n","    train()\n","    acc = test()\n","    clean_accuracies.append(acc)\n","clean_accuracy = clean_accuracies[-1]\n","print(\"Accuracy on clean data:\", clean_accuracy)\n","\n","# Set the accuracy threshold to determine effectiveness\n","threshold = clean_accuracy * 0.9  # 90% of the clean accuracy\n","\n","# Poisoning Attack Functions\n","def node_level_attack(data, poison_rate=0.2):\n","    num_poison = int(poison_rate * data.num_nodes)\n","    for _ in range(num_poison):\n","        node = torch.randint(0, data.num_nodes, (1,))\n","        data.x[node] = torch.rand(data.x[node].shape)  # Randomly alter features\n","    return data\n","\n","def edge_level_attack(data, poison_rate=0.2):\n","    num_poison = int(poison_rate * data.num_edges)\n","    edge_index = data.edge_index.clone()\n","\n","    for _ in range(num_poison):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","def subgraph_attack(data, poison_rate=0.2):\n","    edge_index = data.edge_index.clone()\n","    subgraph_size = int(poison_rate * data.num_nodes)\n","\n","    for _ in range(subgraph_size):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","# Augmentation Functions\n","def node_level_augmentation(data):\n","    data.x = F.dropout(data.x, p=0.1, training=True)\n","    return data\n","\n","def edge_level_augmentation(data):\n","    edge_index = data.edge_index\n","    mask = torch.rand(edge_index.size(1)) > 0.1\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def subgraph_augmentation(data, subgraph_nodes):\n","    edge_index = data.edge_index\n","    for node in subgraph_nodes:\n","        target = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node], [target]], dtype=torch.long)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","    data.edge_index = edge_index\n","    return data\n","\n","def graph_level_augmentation(data):\n","    noise = torch.randn_like(data.x) * 0.1\n","    data.x = data.x + noise\n","    return data\n","\n","# Filtration Methods\n","def structural_relationship_analysis(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if (data.x[node1] - data.x[node2]).norm() > 1.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def feature_manipulation_detection(data):\n","    for node in range(data.num_nodes):\n","        neighbors = data.edge_index[1][data.edge_index[0] == node]\n","        if neighbors.size(0) > 0:\n","            avg_feature = data.x[neighbors].mean(dim=0)\n","            if (data.x[node] - avg_feature).norm() > 0.5:\n","                data.x[node] = avg_feature\n","    return data\n","\n","def edge_alteration_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(node1 - node2) > 10:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def pattern_based_anomaly_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(data.x[node1].sum() - data.x[node2].sum()) > 5.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","# Testing each filtration method's effectiveness after poisoning and augmentations\n","results = {}\n","\n","# Define subgraph nodes for subgraph augmentation\n","subgraph_nodes = torch.randperm(data.num_nodes)[:int(0.1 * data.num_nodes)]\n","\n","# Run each attack, measure accuracy, then apply augmentation and filtration\n","attack_augment_filter_combinations = [\n","    (\"node_level_attack\", node_level_augmentation, structural_relationship_analysis, \"Structural Relationship Analysis\"),\n","    (\"edge_level_attack\", edge_level_augmentation, feature_manipulation_detection, \"Feature Manipulation Detection\"),\n","    (\"subgraph_attack\", lambda d: subgraph_augmentation(d, subgraph_nodes), edge_alteration_detection, \"Edge Alteration Detection\"),\n","    (\"subgraph_attack\", graph_level_augmentation, pattern_based_anomaly_detection, \"Pattern-Based Anomaly Detection\"),\n","]\n","\n","for attack_fn_name, augment_fn, filter_fn, filter_name in attack_augment_filter_combinations:\n","    # Apply attack\n","    attack_fn = globals()[attack_fn_name]\n","    poisoned_data = attack_fn(data.clone())\n","\n","    # Measure accuracy after attack\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    attack_acc = []\n","    for epoch in range(200):\n","        train()\n","        attack_acc.append(test())\n","    attack_accuracy = attack_acc[-1]\n","    print(f\"Accuracy after {attack_fn_name}:\", attack_accuracy)\n","\n","    # Calculate attack success rate\n","    attack_success_rate = (clean_accuracy - attack_accuracy) / clean_accuracy\n","    print(f\"Attack Success Rate for {attack_fn_name}: {attack_success_rate * 100:.2f}%\")\n","\n","    # Apply augmentation and measure accuracy\n","    augmented_data = augment_fn(poisoned_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    augmented_acc = []\n","    for epoch in range(200):\n","        train()\n","        augmented_acc.append(test())\n","    augmented_accuracy = augmented_acc[-1]\n","    print(f\"Accuracy after augmentation ({augment_fn.__name__}):\", augmented_accuracy)\n","\n","    # Apply filtration method and measure final accuracy\n","    filtered_data = filter_fn(augmented_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    filtered_acc = []\n","    for epoch in range(200):\n","        train()\n","        filtered_acc.append(test())\n","    final_accuracy = filtered_acc[-1]\n","    print(f\"Accuracy after filtration ({filter_name}):\", final_accuracy)\n","\n","    # Store results and evaluate against the threshold\n","    results[filter_name] = {\n","        \"poisoned_accuracy\": attack_accuracy,\n","        \"augmented_accuracy\": augmented_accuracy,\n","        \"filtered_accuracy\": final_accuracy,\n","        \"is_effective\": final_accuracy >= threshold,\n","        \"attack_success_rate\": attack_success_rate * 100  # Converted to percentage\n","    }\n","\n","# Display results\n","print(\"\\nFinal Results:\")\n","for filter_name, result in results.items():\n","    print(f\"{filter_name}:\")\n","    print(f\"  Accuracy after attack: {result['poisoned_accuracy']}\")\n","    print(f\"  Attack Success Rate: {result['attack_success_rate']:.2f}%\")\n","    print(f\"  Accuracy after augmentation: {result['augmented_accuracy']}\")\n","    print(f\"  Accuracy after filtration: {result['filtered_accuracy']}\")\n","    print(f\"  Is effective (meets threshold): {result['is_effective']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2rZ4XPIrHlLR"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.transforms import NormalizeFeatures\n","from sklearn.metrics import accuracy_score\n","\n","# Load and preprocess PubMed dataset\n","dataset = Planetoid(root='/tmp/PubMed', name='PubMed', transform=NormalizeFeatures())\n","data = dataset[0]\n","\n","# Define GNN model\n","class GCN(torch.nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_features, 16)\n","        self.conv2 = GCNConv(16, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize model, optimizer, and data\n","model = GCN()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","data = data.to(device)\n","model = model.to(device)\n","\n","# Function to train the model\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test():\n","    model.eval()\n","    out = model(data)\n","    pred = out.argmax(dim=1)\n","    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n","    return acc\n","\n","# Train and evaluate on clean data\n","clean_accuracies = []\n","for epoch in range(200):\n","    train()\n","    acc = test()\n","    clean_accuracies.append(acc)\n","clean_accuracy = clean_accuracies[-1]\n","print(\"Accuracy on clean data:\", clean_accuracy)\n","\n","# Set the accuracy threshold to determine effectiveness\n","threshold = clean_accuracy * 0.9  # 90% of the clean accuracy\n","\n","# Poisoning Attack Functions\n","def node_level_attack(data, poison_rate=0.2):\n","    num_poison = int(poison_rate * data.num_nodes)\n","    for _ in range(num_poison):\n","        node = torch.randint(0, data.num_nodes, (1,))\n","        data.x[node] = torch.rand(data.x[node].shape)  # Randomly alter features\n","    return data\n","\n","def edge_level_attack(data, poison_rate=0.2):\n","    num_poison = int(poison_rate * data.edge_index.size(1))\n","    edge_index = data.edge_index.clone()\n","\n","    for _ in range(num_poison):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long).to(device)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","def subgraph_attack(data, poison_rate=0.2):\n","    edge_index = data.edge_index.clone()\n","    subgraph_size = int(poison_rate * data.num_nodes)\n","\n","    for _ in range(subgraph_size):\n","        node1 = torch.randint(0, data.num_nodes, (1,))\n","        node2 = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node1.item()], [node2.item()]], dtype=torch.long).to(device)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","\n","    data.edge_index = edge_index\n","    return data\n","\n","# Augmentation Functions\n","def node_level_augmentation(data):\n","    data.x = F.dropout(data.x, p=0.1, training=True)\n","    return data\n","\n","def edge_level_augmentation(data):\n","    edge_index = data.edge_index\n","    mask = torch.rand(edge_index.size(1)) > 0.1\n","    data.edge_index = edge_index[:, mask.to(device)]\n","    return data\n","\n","def subgraph_augmentation(data, subgraph_nodes):\n","    edge_index = data.edge_index\n","    for node in subgraph_nodes:\n","        target = torch.randint(0, data.num_nodes, (1,))\n","        new_edge = torch.tensor([[node.item()], [target.item()]], dtype=torch.long).to(device)\n","        edge_index = torch.cat([edge_index, new_edge], dim=1)\n","    data.edge_index = edge_index\n","    return data\n","\n","def graph_level_augmentation(data):\n","    noise = torch.randn_like(data.x) * 0.1\n","    data.x = data.x + noise\n","    return data\n","\n","# Filtration Methods\n","def structural_relationship_analysis(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool).to(device)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if (data.x[node1] - data.x[node2]).norm() > 1.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def feature_manipulation_detection(data):\n","    for node in range(data.num_nodes):\n","        neighbors = data.edge_index[1][data.edge_index[0] == node]\n","        if neighbors.size(0) > 0:\n","            avg_feature = data.x[neighbors].mean(dim=0)\n","            if (data.x[node] - avg_feature).norm() > 0.5:\n","                data.x[node] = avg_feature\n","    return data\n","\n","def edge_alteration_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool).to(device)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(node1 - node2) > 10:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","def pattern_based_anomaly_detection(data):\n","    edge_index = data.edge_index.clone()\n","    mask = torch.ones(edge_index.size(1), dtype=torch.bool).to(device)\n","    for i in range(edge_index.size(1)):\n","        node1, node2 = edge_index[:, i]\n","        if torch.abs(data.x[node1].sum() - data.x[node2].sum()) > 5.0:\n","            mask[i] = False\n","    data.edge_index = edge_index[:, mask]\n","    return data\n","\n","# Testing each filtration method's effectiveness after poisoning and augmentations\n","results = {}\n","\n","# Define subgraph nodes for subgraph augmentation\n","subgraph_nodes = torch.randperm(data.num_nodes)[:int(0.1 * data.num_nodes)].to(device)\n","\n","# Run each attack, measure accuracy, then apply augmentation and filtration\n","attack_augment_filter_combinations = [\n","    (\"node_level_attack\", node_level_augmentation, structural_relationship_analysis, \"Structural Relationship Analysis\"),\n","    (\"edge_level_attack\", edge_level_augmentation, feature_manipulation_detection, \"Feature Manipulation Detection\"),\n","    (\"subgraph_attack\", lambda d: subgraph_augmentation(d, subgraph_nodes), edge_alteration_detection, \"Edge Alteration Detection\"),\n","    (\"subgraph_attack\", graph_level_augmentation, pattern_based_anomaly_detection, \"Pattern-Based Anomaly Detection\"),\n","]\n","\n","for attack_fn_name, augment_fn, filter_fn, filter_name in attack_augment_filter_combinations:\n","    # Apply attack\n","    attack_fn = globals()[attack_fn_name]\n","    poisoned_data = attack_fn(data.clone())\n","\n","    # Measure accuracy after attack\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    attack_acc = []\n","    for epoch in range(200):\n","        train()\n","        attack_acc.append(test())\n","    attack_accuracy = attack_acc[-1]\n","    print(f\"Accuracy after {attack_fn_name}:\", attack_accuracy)\n","\n","    # Calculate attack success rate\n","    attack_success_rate = (clean_accuracy - attack_accuracy) / clean_accuracy\n","    print(f\"Attack Success Rate for {attack_fn_name}: {attack_success_rate * 100:.2f}%\")\n","\n","    # Apply augmentation and measure accuracy\n","    augmented_data = augment_fn(poisoned_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    augmented_acc = []\n","    for epoch in range(200):\n","        train()\n","        augmented_acc.append(test())\n","    augmented_accuracy = augmented_acc[-1]\n","    print(f\"Accuracy after augmentation ({augment_fn.__name__}):\", augmented_accuracy)\n","\n","    # Apply filtration method and measure final accuracy\n","    filtered_data = filter_fn(augmented_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    filtered_acc = []\n","    for epoch in range(200):\n","        train()\n","        filtered_acc.append(test())\n","    final_accuracy = filtered_acc[-1]\n","    print(f\"Accuracy after filtration ({filter_name}):\", final_accuracy)\n","\n","    # Store results and evaluate against the threshold\n","    results[filter_name] = {\n","        \"poisoned_accuracy\": attack_accuracy,\n","        \"augmented_accuracy\": augmented_accuracy,\n","        \"filtered_accuracy\": final_accuracy,\n","        \"is_effective\": final_accuracy >= threshold,\n","        \"attack_success_rate\": attack_success_rate * 100  # Converted to percentage\n","    }\n","\n","# Display results\n","print(\"\\nFinal Results:\")\n","for filter_name, result in results.items():\n","    print(f\"{filter_name}:\")\n","    print(f\"  Accuracy after attack: {result['poisoned_accuracy']}\")\n","    print(f\"  Attack Success Rate: {result['attack_success_rate']:.2f}%\")\n","    print(f\"  Accuracy after augmentation: {result['augmented_accuracy']}\")\n","    print(f\"  Accuracy after filtration: {result['filtered_accuracy']}\")\n","    print(f\"  Is effective (meets threshold): {result['is_effective']}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gd4VhJTpSNw8","executionInfo":{"status":"ok","timestamp":1731145526269,"user_tz":-60,"elapsed":331384,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"}},"outputId":"59861170-d36d-42bf-d65e-ca81a0ff5922"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on clean data: 0.8\n","Accuracy after node_level_attack: 0.797\n","Attack Success Rate for node_level_attack: 0.38%\n","Accuracy after augmentation (node_level_augmentation): 0.794\n","Accuracy after filtration (Structural Relationship Analysis): 0.792\n","Accuracy after edge_level_attack: 0.793\n","Attack Success Rate for edge_level_attack: 0.88%\n","Accuracy after augmentation (edge_level_augmentation): 0.794\n","Accuracy after filtration (Feature Manipulation Detection): 0.794\n","Accuracy after subgraph_attack: 0.795\n","Attack Success Rate for subgraph_attack: 0.63%\n","Accuracy after augmentation (<lambda>): 0.794\n","Accuracy after filtration (Edge Alteration Detection): 0.792\n","Accuracy after subgraph_attack: 0.789\n","Attack Success Rate for subgraph_attack: 1.38%\n","Accuracy after augmentation (graph_level_augmentation): 0.79\n","Accuracy after filtration (Pattern-Based Anomaly Detection): 0.799\n","\n","Final Results:\n","Structural Relationship Analysis:\n","  Accuracy after attack: 0.797\n","  Attack Success Rate: 0.38%\n","  Accuracy after augmentation: 0.794\n","  Accuracy after filtration: 0.792\n","  Is effective (meets threshold): True\n","Feature Manipulation Detection:\n","  Accuracy after attack: 0.793\n","  Attack Success Rate: 0.88%\n","  Accuracy after augmentation: 0.794\n","  Accuracy after filtration: 0.794\n","  Is effective (meets threshold): True\n","Edge Alteration Detection:\n","  Accuracy after attack: 0.795\n","  Attack Success Rate: 0.63%\n","  Accuracy after augmentation: 0.794\n","  Accuracy after filtration: 0.792\n","  Is effective (meets threshold): True\n","Pattern-Based Anomaly Detection:\n","  Accuracy after attack: 0.789\n","  Attack Success Rate: 1.38%\n","  Accuracy after augmentation: 0.79\n","  Accuracy after filtration: 0.799\n","  Is effective (meets threshold): True\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_Lqri0pnSN2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import TUDataset\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.transforms import NormalizeFeatures\n","from sklearn.metrics import accuracy_score\n","\n","# Load and preprocess MUTAG dataset\n","dataset = TUDataset(root='/tmp/MUTAG', name='MUTAG', transform=NormalizeFeatures())\n","data = dataset[0]\n","\n","# Define GNN model for graph classification\n","class GCN(torch.nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_features, 16)\n","        self.conv2 = GCNConv(16, 16)\n","        self.fc = torch.nn.Linear(16, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = F.relu(self.conv2(x, edge_index))\n","        x = global_mean_pool(x, batch)  # Aggregate node features for each graph\n","        return F.log_softmax(self.fc(x), dim=1)\n","\n","# Initialize model, optimizer, and data\n","model = GCN()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","# Function to train the model\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data.to(device))\n","    loss = F.nll_loss(out, data.y.to(device))\n","    loss.backward()\n","    optimizer.step()\n","\n","# Function to test the model\n","def test():\n","    model.eval()\n","    out = model(data.to(device))\n","    pred = out.argmax(dim=1)\n","    acc = accuracy_score(data.y.cpu(), pred.cpu())\n","    return acc\n","\n","# Train and evaluate on clean data\n","clean_accuracies = []\n","for epoch in range(200):\n","    train()\n","    acc = test()\n","    clean_accuracies.append(acc)\n","clean_accuracy = clean_accuracies[-1]\n","print(\"Accuracy on clean data:\", clean_accuracy)\n","\n","# Set the accuracy threshold to determine effectiveness\n","threshold = clean_accuracy * 0.9  # 90% of the clean accuracy\n","\n","# Poisoning Attack and Augmentation/Filtration Functions (unchanged)\n","# Note: Use the same functions for attacks, augmentations, and filtrations as in the original code.\n","\n","# Testing each filtration method's effectiveness after poisoning and augmentations\n","results = {}\n","\n","# Define subgraph nodes for subgraph augmentation\n","subgraph_nodes = torch.randperm(data.num_nodes)[:int(0.1 * data.num_nodes)].to(device)\n","\n","# Run each attack, measure accuracy, then apply augmentation and filtration\n","attack_augment_filter_combinations = [\n","    (\"node_level_attack\", node_level_augmentation, structural_relationship_analysis, \"Structural Relationship Analysis\"),\n","    (\"edge_level_attack\", edge_level_augmentation, feature_manipulation_detection, \"Feature Manipulation Detection\"),\n","    (\"subgraph_attack\", lambda d: subgraph_augmentation(d, subgraph_nodes), edge_alteration_detection, \"Edge Alteration Detection\"),\n","    (\"subgraph_attack\", graph_level_augmentation, pattern_based_anomaly_detection, \"Pattern-Based Anomaly Detection\"),\n","]\n","\n","for attack_fn_name, augment_fn, filter_fn, filter_name in attack_augment_filter_combinations:\n","    # Apply attack\n","    attack_fn = globals()[attack_fn_name]\n","    poisoned_data = attack_fn(data.clone())\n","\n","    # Measure accuracy after attack\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    attack_acc = []\n","    for epoch in range(200):\n","        train()\n","        attack_acc.append(test())\n","    attack_accuracy = attack_acc[-1]\n","    print(f\"Accuracy after {attack_fn_name}:\", attack_accuracy)\n","\n","    # Calculate attack success rate\n","    attack_success_rate = (clean_accuracy - attack_accuracy) / clean_accuracy\n","    print(f\"Attack Success Rate for {attack_fn_name}: {attack_success_rate * 100:.2f}%\")\n","\n","    # Apply augmentation and measure accuracy\n","    augmented_data = augment_fn(poisoned_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    augmented_acc = []\n","    for epoch in range(200):\n","        train()\n","        augmented_acc.append(test())\n","    augmented_accuracy = augmented_acc[-1]\n","    print(f\"Accuracy after augmentation ({augment_fn.__name__}):\", augmented_accuracy)\n","\n","    # Apply filtration method and measure final accuracy\n","    filtered_data = filter_fn(augmented_data.clone())\n","    model = GCN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","    filtered_acc = []\n","    for epoch in range(200):\n","        train()\n","        filtered_acc.append(test())\n","    final_accuracy = filtered_acc[-1]\n","    print(f\"Accuracy after filtration ({filter_name}):\", final_accuracy)\n","\n","    # Store results and evaluate against the threshold\n","    results[filter_name] = {\n","        \"poisoned_accuracy\": attack_accuracy,\n","        \"augmented_accuracy\": augmented_accuracy,\n","        \"filtered_accuracy\": final_accuracy,\n","        \"is_effective\": final_accuracy >= threshold,\n","        \"attack_success_rate\": attack_success_rate * 100  # Converted to percentage\n","    }\n","\n","# Display results\n","print(\"\\nFinal Results:\")\n","for filter_name, result in results.items():\n","    print(f\"{filter_name}:\")\n","    print(f\"  Accuracy after attack: {result['poisoned_accuracy']}\")\n","    print(f\"  Attack Success Rate: {result['attack_success_rate']:.2f}%\")\n","    print(f\"  Accuracy after augmentation: {result['augmented_accuracy']}\")\n","    print(f\"  Accuracy after filtration: {result['filtered_accuracy']}\")\n","    print(f\"  Is effective (meets threshold): {result['is_effective']}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-mZhW_3myCv","executionInfo":{"status":"ok","timestamp":1731150471868,"user_tz":-60,"elapsed":29760,"user":{"displayName":"ADIL AHMAD","userId":"15040140492227092703"}},"outputId":"cb4e892f-8ac9-4e99-d827-10739f369048"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n","Processing...\n","Done!\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy on clean data: 1.0\n","Accuracy after node_level_attack: 1.0\n","Attack Success Rate for node_level_attack: 0.00%\n","Accuracy after augmentation (node_level_augmentation): 1.0\n","Accuracy after filtration (Structural Relationship Analysis): 1.0\n","Accuracy after edge_level_attack: 1.0\n","Attack Success Rate for edge_level_attack: 0.00%\n","Accuracy after augmentation (edge_level_augmentation): 1.0\n","Accuracy after filtration (Feature Manipulation Detection): 1.0\n","Accuracy after subgraph_attack: 1.0\n","Attack Success Rate for subgraph_attack: 0.00%\n","Accuracy after augmentation (<lambda>): 1.0\n","Accuracy after filtration (Edge Alteration Detection): 1.0\n","Accuracy after subgraph_attack: 1.0\n","Attack Success Rate for subgraph_attack: 0.00%\n","Accuracy after augmentation (graph_level_augmentation): 1.0\n","Accuracy after filtration (Pattern-Based Anomaly Detection): 1.0\n","\n","Final Results:\n","Structural Relationship Analysis:\n","  Accuracy after attack: 1.0\n","  Attack Success Rate: 0.00%\n","  Accuracy after augmentation: 1.0\n","  Accuracy after filtration: 1.0\n","  Is effective (meets threshold): True\n","Feature Manipulation Detection:\n","  Accuracy after attack: 1.0\n","  Attack Success Rate: 0.00%\n","  Accuracy after augmentation: 1.0\n","  Accuracy after filtration: 1.0\n","  Is effective (meets threshold): True\n","Edge Alteration Detection:\n","  Accuracy after attack: 1.0\n","  Attack Success Rate: 0.00%\n","  Accuracy after augmentation: 1.0\n","  Accuracy after filtration: 1.0\n","  Is effective (meets threshold): True\n","Pattern-Based Anomaly Detection:\n","  Accuracy after attack: 1.0\n","  Attack Success Rate: 0.00%\n","  Accuracy after augmentation: 1.0\n","  Accuracy after filtration: 1.0\n","  Is effective (meets threshold): True\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FrukYbRym2qx"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"10TwCtUBSqFvGXxnd1PjHhj3K5fBcUwen","authorship_tag":"ABX9TyP33BIvJa0nqxLgnXiIUhpl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}